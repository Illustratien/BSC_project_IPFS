[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "20503C Studienprojekt: stomata distribution in cereal and other species",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nR\nHW\nPractical\n\n\n\n\n1\nTue, Apr 16\nGeneral introduction\nData type, R Studio\n\n\n\n\n2\nTue, Apr 23\nLecture 1 - Physiological role of Stomata\nworking directory, accessing element from data\nGithub\n\n\n\n3\nTue, Apr 30\nLecture 2 - Physiological role of Stomata\ndataframe operation and ggplot\ndata structure dplyr and more ggplot\n\n\n\n4\nTue, May 07\nScientific presentation\ndataframe operation\nmutate across\nfirst experience\n\n\n5\nTue, May 14\n\ncolumn editing and column replacement\n\nphenotyping start!\n\n\n6\nTue, May 21\n\napplying functions to targeted columns and groups\nsummarise group_by\n\n\n\n7\nTue, May 28\n\nsummarize, shape transformation of dataframe\nfor loop1 for loop2\n\n\n\n8\nTue, Jun 04\n\ncombine files in a loop\n\n\n\n\n9\nTue, Jun 11\n\nanalysis planning and results visualization\nData visualization manuscript arrange plots\n\n\n\n10\nTue, Jun 18\n\n\n\n\n\n\n11\nTue, Jun 25\n\n\n\n\n\n\n12\nTue, Jul 02\n\nStatistic analysis\n\n\n\n\n13\nTue, Jul 09\n\nReporting with quarto\n\n\n\n\n14\nTue, Jul 16\nFinal oral presentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nWeek7: Grain development III\n\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek8: Grain development Iv\n\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek9: Grain development v\n\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2023\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek1: R studio and vector\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek1: R studio, vector and function\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek2: Working directory and accessor\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek3: dataframe and ggplot2\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek4: column and row operations in dataframe\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek5: pattern matching in dataframe\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\n  \n\n\n\n\nWeek6: function and groups\n\n\n\n\n\n\n\n\n\n\n\n\nTien-Cheng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog was build for the IPFS BSC project course 2023 summer semester."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Week1/index.html",
    "href": "posts/Week1/index.html",
    "title": "Week1: R studio, vector and function",
    "section": "",
    "text": "Welcome to the first course! During the following 2 hrs, you will learn data type of vectors, function and %&gt;%."
  },
  {
    "objectID": "posts/Week3/index.html",
    "href": "posts/Week3/index.html",
    "title": "Week3: dataframe and ggplot2",
    "section": "",
    "text": "Welcome to the third course! You will learn ggplot and dataframe wrangling:\nReview game Kahoot!"
  },
  {
    "objectID": "posts/Week3/index.html#read-data-and-rproject",
    "href": "posts/Week3/index.html#read-data-and-rproject",
    "title": "Week3: Spikelet development",
    "section": "0.1 Read data and Rproject",
    "text": "0.1 Read data and Rproject\n\n0.1.1 practice dataframe with real data\n\ndata <- read.csv(\"data/ear_summarized.csv\")\n# data %>% str()\ndata %>% glimpse()\nnames(data)\n# extract column from dataframe\ndata$BBCH\ndata %>% unique()\n\n# summarize dataframe\nlapply(data, range)\n# turn as data frame\nlapply(data, range) %>% data.frame()\n\nsummary(data)"
  },
  {
    "objectID": "posts/Week3/index.html#data-format-overview",
    "href": "posts/Week3/index.html#data-format-overview",
    "title": "Week3: Spikelet development",
    "section": "3 Data format overview",
    "text": "3 Data format overview\n\ndat <-read.csv('./data/kernel_combine.csv',\n               header = T,stringsAsFactors = F) %>%\n  dplyr::filter(tiller==\"M\")\nglimpse(dat)\ndat %>% \n  group_by(car,var,nitrogen,time,rep) %>% \n  distinct()"
  },
  {
    "objectID": "posts/Week3/index.html#classify-spikelet-based-on-position",
    "href": "posts/Week3/index.html#classify-spikelet-based-on-position",
    "title": "Week3: Spikelet development",
    "section": "4 classify spikelet based on position",
    "text": "4 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\ndat %<>%\n  group_by(car,var,nitrogen,time,rep) %>% \n  mutate(type=cut(spike,3) %>% as.numeric(),\n         type=case_when(type==1~\"basal\",\n                        type==2~\"central\",\n                        T~\"apical\")) %>% \n  group_by(car,var,nitrogen,time,rep,type) %>% \n  dplyr::arrange(spike) %>% \n  mutate(Fl=seq(1,n())) %>% \n  dplyr::arrange(var,nitrogen,time,rep,spike)\nglimpse(dat)\n\nRows: 4,749\nColumns: 13\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          <int> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ~\n$ nitrogen     <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1~\n$ time         <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Al~\n$ rep          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, ~\n$ tiller       <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1,~\n$ flower       <int> 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 2, 2, ~\n$ kernel.full  <int> 0, 0, 1, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 2, 1, 2, 0, 0, 0, ~\n$ kernel.half  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         <chr> \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ce~\n$ Fl           <int> 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, ~"
  },
  {
    "objectID": "posts/Week3/index.html#lookuptable-of-treatment-not-yet",
    "href": "posts/Week3/index.html#lookuptable-of-treatment-not-yet",
    "title": "Week3: Spikelet development",
    "section": "4 lookuptable of treatment (not yet)",
    "text": "4 lookuptable of treatment (not yet)"
  },
  {
    "objectID": "posts/Week3/index.html#basic-summary-of-kernel-development-summ-for-single-spike",
    "href": "posts/Week3/index.html#basic-summary-of-kernel-development-summ-for-single-spike",
    "title": "Week3: Spikelet development",
    "section": "5 basic summary of kernel development summ for single spike",
    "text": "5 basic summary of kernel development summ for single spike\nSp: total spikelet Fl: maximum floret sfl: total floret kf: total full kernel kh: total half kernel ks: total small kernel kp: potential kernel number fr: filling rate fc: potential filling rate\n\nsum.dat <- dat %>% \n  dplyr::group_by(nitrogen,time,var,rep,tiller,type) %>% \n  dplyr::summarise(\n    Sp=max(spike),#total spikelet\n    Fl=max(flower),# maximum floret \n    sfl=sum(flower),# total floret\n    kf=sum(kernel.full),# total full kernel\n    kh=sum(kernel.half),# total half kernel\n    ks=sum(kernel.small),# total small kernel\n    kp=kf+kh,# potential kernel number \n    fr=kf/sfl,# filling rate \n    fc=kf/kp)#potential filling rate\nglimpse(sum.dat)\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~"
  },
  {
    "objectID": "posts/Week3/index.html#data-wrangling-and-plot-with-facet",
    "href": "posts/Week3/index.html#data-wrangling-and-plot-with-facet",
    "title": "Week3: Spikelet development",
    "section": "6 Data wrangling and plot with facet",
    "text": "6 Data wrangling and plot with facet\n\nlong_format <- dat %>% \n  tidyr::pivot_longer(cols=c(nitrogen,time),\n                      names_to = \"treatment\",\n                      values_to = \"levels\") %>% \n  group_by(spike,var,treatment,levels,type,rep) %>%\n  summarise(fertile_flower=max(kernel.full)) %>% \n  group_by(spike,var,treatment,levels,type) %>%\n  summarise(fertile_flower=mean(fertile_flower))\n\nlong_format%>% \n  filter(fertile_flower<10) %>% \n  ggplot(aes(fertile_flower,spike,color=type,shape=levels))+\n  geom_point()+\n  facet_grid(treatment~var)+\n  theme_classic()+\n  scale_x_continuous(limits = c(0,5),breaks=seq(0,4))"
  },
  {
    "objectID": "posts/Week1/index.html#working-directory",
    "href": "posts/Week1/index.html#working-directory",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1 Working directory",
    "text": "1 Working directory\n\ngetwd()\n# read.csv()# try to read one file"
  },
  {
    "objectID": "posts/Week1/index.html#concept-of-datatype-case-sensitive",
    "href": "posts/Week1/index.html#concept-of-datatype-case-sensitive",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.1 Concept of datatype & case sensitive",
    "text": "1.1 Concept of datatype & case sensitive\n\nvariable\n# assignment str\"v\" to name \"variable\"\n## \"\" and unquote str and variable \n\nvariable <- \"v\"\nVariable <- 1\nvariable +1\nVariable +1"
  },
  {
    "objectID": "posts/Week1/index.html#the-reason-of-error-data-type",
    "href": "posts/Week1/index.html#the-reason-of-error-data-type",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "3 the reason of error – data type",
    "text": "3 the reason of error – data type\n\n# str??\nstr\n?str\nstr(variable)\nstr(Variable)\n# data type coersion\nstr(NA)\nstr(c(NA,1))\nstr(c(NA,\"a\"))\nstr(c(NA,TRUE))\nstr(c(1,\"a\"))"
  },
  {
    "objectID": "posts/Week1/index.html#function-argument1-argument2",
    "href": "posts/Week1/index.html#function-argument1-argument2",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "0.4 function (argument1, argument2)",
    "text": "0.4 function (argument1, argument2)\n\nc(1,2,3)\nseq(1,3,1)\n# embeded function fun2(fun1(argument))\nlength(c(1,2,3))\nstr(c(1,2,3))\n\nrep(1,3)\nrep(1,3) %>% unique()\nrep(1,3) %>% cumsum()"
  },
  {
    "objectID": "posts/Week1/index.html#write-your-first-function",
    "href": "posts/Week1/index.html#write-your-first-function",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.6 write your first function",
    "text": "1.6 write your first function\n\nplusone <- function(x){x+1}\n# is function data type sensitive?\nplusone(variable)\nplusone(Variable)\n\n\n\n\n\n\n\nChallenge\n\n\n\nwrite a average function and check whether input is numeric if not return with warning *first write your function in text"
  },
  {
    "objectID": "posts/Week1/index.html#function-argument1-argument2-code",
    "href": "posts/Week1/index.html#function-argument1-argument2-code",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "4 function (argument1, argument2) {code}",
    "text": "4 function (argument1, argument2) {code}\n\nc(1,2,3)\nseq(1,3,1)\n# embeded function fun2(fun1(argument))\nlength(c(1,2,3))\nstr(c(1,2,3))\n\nrep(1,3)\nrep(1,3) %>% unique()\nrep(1,3) %>% cumsum()"
  },
  {
    "objectID": "posts/Week1/index.html#indexing",
    "href": "posts/Week1/index.html#indexing",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "6 indexing",
    "text": "6 indexing\n\n3%in%c(1,3) \n2%in%c(1,3) \n1==2 \n!1==2 \n1!=2 \nwhich(c(1,3)==3) \norder(c(3,1,2)) \nc(3,1,2) %>% .[order(.)]\n\nc(1,2,NA) %>% is.na() c(1,2,NA) %>% is.na() %>% which() c(1,2,NA) %>% is.na() %>% !. c(1,2,NA) %>% !is.na() !is.na(c(1,2,NA) )\n\n\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\n           temp=c(20,15,13), \n           thermal_time=cumsum(temp))\n\ndf <- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\n                 temp=c(20,15,13), thermal_time=cumsum(c(20,15,13)))\n\ndf$temp %>% str()\ndf[\"temp\"] %>% str()\ndf[,\"temp\"] %>% str()\ndf[[\"temp\"]] %>% str()"
  },
  {
    "objectID": "posts/Week1/index.html#check-data-type",
    "href": "posts/Week1/index.html#check-data-type",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.2 Check data type",
    "text": "1.2 Check data type\n\n# str??\nstr\n?str\nstr(variable)\nstr(Variable)\n# data type coersion\nstr(NA)\nstr(c(NA,1))\nstr(c(NA,\"a\"))\nstr(c(NA,TRUE))\nstr(c(1,\"a\"))"
  },
  {
    "objectID": "posts/Week1/index.html#function-something-with",
    "href": "posts/Week1/index.html#function-something-with",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.3 Function: something with ()",
    "text": "1.3 Function: something with ()\nformat: function_name(argument1, argument2) {code}\n\n# how many ways of creating sequence?\nc(1,2,3)\nseq(1,3,1)\n\n# embeded function fun2(fun1())\nlength(c(1,2,3))\n# use pipe, . is the result of previous step\nc(1,2,3) %>% length(.)\n\n# what is the data type?\nstr(c(1,2,3))\n\n# replicate\nrep(1,3)\nrep(1,3) %>% unique()\nrep(1,3) %>% cumsum()\n\npaste(c(\"a\",\"1\"),collapse = \"\")\npaste0(c(\"a\",\"1\"))\n\n\n\n\n\n\n\nChallenge\n\n\n\nhow to use pasteand repto create sequence of char vector c(“a1”,“b1”,“a2”,“b2”)?\n\n\n\n\n[1] \"a1\" \"a2\" \"b1\" \"b2\"\n\n\n[1] \"a1\" \"b1\" \"a2\" \"b2\""
  },
  {
    "objectID": "posts/Week1/index.html#pattern-matching-logical-vector-and-its-position",
    "href": "posts/Week1/index.html#pattern-matching-logical-vector-and-its-position",
    "title": "Week1: R studio and vector",
    "section": "5 Pattern matching: logical vector and its position",
    "text": "5 Pattern matching: logical vector and its position\n\n\n\nLogical vector\n\n\n\n# check if pattern exist in vector\n3%in%c(1,3) \n2%in%c(1,3) \n\n1==2 \n!1==2 \n1!=2 \nc(1,3)==2\n\nwhich(c(1,3)==3) \n\n# what will be the difference?\norder(c(3,1,2)) \nc(3,1,2) %&gt;% .[order(.)]\n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week1/index.html#indexing-something-with-or",
    "href": "posts/Week1/index.html#indexing-something-with-or",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.8 Indexing something with [] or $",
    "text": "1.8 Indexing something with [] or $\n\n# why this will not work?\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\n           temp=c(20,15,13), \n           thermal_time=cumsum(temp))\ndf\n\n\n\n\n\n\n\nChallenge\n\n\n\ncreate data frame to calculate thermal time\n\n\n\n\n        time temp thermal_time\n1 2023-04-17   20           20\n2 2023-04-18   15           35\n3 2023-04-19   13           48\n\n\n\n# which is of type dataframe?\ndf$temp %>% str()\ndf[\"temp\"] %>% str()\ndf[,\"temp\"] %>% str()\ndf[[\"temp\"]] %>% str()"
  },
  {
    "objectID": "posts/Week1/index.html#date",
    "href": "posts/Week1/index.html#date",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.5 Date",
    "text": "1.5 Date\n\n\n\n\n\n\n\n\n\nChallenge\n\n\n\nif Date is additive, how to create successive Date vector? Date start with “2023-04-17”\n\n\n\n\n[1] \"2023-04-17\" \"2023-04-18\" \"2023-04-19\" \"2023-04-20\" \"2023-04-21\""
  },
  {
    "objectID": "posts/Week1/index.html#r-packages",
    "href": "posts/Week1/index.html#r-packages",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.4 r packages",
    "text": "1.4 r packages\nhttps://dplyr.tidyverse.org/"
  },
  {
    "objectID": "posts/Week1/index.html#name-rules",
    "href": "posts/Week1/index.html#name-rules",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.9 name rules",
    "text": "1.9 name rules"
  },
  {
    "objectID": "posts/Week1/index.html#section",
    "href": "posts/Week1/index.html#section",
    "title": "Week1: The growth of spike in winter wheat",
    "section": "1.10 ",
    "text": "1.10 \n#Plot Open Ear_development_BSC_project.Rproj, go to file, src, open Week1.R ## Working directory\n\ngetwd()\n# read.csv()# try to read one file"
  },
  {
    "objectID": "posts/Week2/index.html",
    "href": "posts/Week2/index.html",
    "title": "Week2: Working directory and accessor",
    "section": "",
    "text": "Welcome to the second course! You will learn working directory, subset elements from vector, list and dataframe."
  },
  {
    "objectID": "posts/Week2/index.html#plot",
    "href": "posts/Week2/index.html#plot",
    "title": "Week2: The growth of spike in winter wheat",
    "section": "Plot",
    "text": "Plot\n\nGGplot2\nRequirements of scientific plot. 1. axis title with unit if there is any.\n\nlegend title full name instead of default abbreviation.\n\nFigure title.\nggplot 2 ggplot gallery\n\nlibrary(ggplot)\nlibrary(ggplot2)\n\n\ndata %>% \nggplot(aes(x=date,y=weight,color=var))+\ngeom_point()+\ngeom_line(aes(group=group))+ # link the point by group.\nxlab(\"date of harvest\")+ #x axis title\nylab(\"ear weight(g)\")+   #y axis title\nguides(color=guide_legend(title=\"Cultivar\")) #change legend title \n\n\n\n\nFigure 1: Growth of ear weight over time.\n\n\n\n\n\n\n\n\n\n\nChallenge\n\n\n\nuse theme_xx() function series to change background of the plot. Find your favorite one.\n\n\n\n\n\n\n\ndark theme example."
  },
  {
    "objectID": "posts/Week2/index.html#discussion-goes-here",
    "href": "posts/Week2/index.html#discussion-goes-here",
    "title": "Week2: The growth of spike in winter wheat",
    "section": "Discussion goes here",
    "text": "Discussion goes here"
  },
  {
    "objectID": "posts/Week3/index.html#plot",
    "href": "posts/Week3/index.html#plot",
    "title": "Week3: Spikelet development",
    "section": "2 Plot",
    "text": "2 Plot\n\n2.1 GGplot2\nggplot grammar: layer wise command, order is important!\nTop layer ggplot()and sub-layers sublayer_command(), they are separated by +.\nWithin each layer, there may be an aesthetic function aes() to set aesthetic setting like x,y and color,fill or shape. Function ggplot() will not generate any graph but used for setting common aesthetic setting across the sub-layer. Plot type are specify in sub-layer with prefix geom_xx.\n\n\n\nlayers of ggplot: click picture for original source\n\n\n Requirements of scientific plot.3.3 More reference: ggplot 2 ggplot gallery\n\naxis title: specify with unit if there is any using xlab() or ylab().\nlegend title: full name instead of default abbreviation using guides().\n\n\n# Watch out the names!\nlibrary(ggplot)\nlibrary(ggplot2)\n\n\ndata %>% \n  ggplot(aes(x=date,y=weight,color=var))+\n  geom_point()+\n  geom_line(aes(group=group))+ # link the point by group.\n  xlab(\"date of harvest\")+ #x axis title\n  ylab(\"ear weight(g)\")+   #y axis title\n  guides(color=guide_legend(title=\"Cultivar\")) #change legend title \n\n\n\n\nFigure 1: Growth of ear weight over time.\n\n\n\n\n\n\n\n\n\n\nChallenge\n\n\n\nuse theme_xx() function series to change background of the plot. Find your favorite one.\n\n\n\n\n\n\n\ndark theme example."
  },
  {
    "objectID": "posts/Week3/index.html#dplyr",
    "href": "posts/Week3/index.html#dplyr",
    "title": "Week3: dataframe and ggplot2",
    "section": "1 dplyr",
    "text": "1 dplyr\n\n1.1 Subset row(s)\ndplyr::filter(): extract row where the condition matched. 22 r_package::function_name specify the function name by package name.:: has similar meaning like “from”. It is useful to avoid name space conflict when same function name is used by multiple library that you are using.\ne.g., extract temp where time is 2023-04-17 in df.\n\n# df$time %&gt;% str()\ndf %&gt;% dplyr::filter(time=='2023-04-17') %&gt;% .$temp\ndf %&gt;% dplyr::filter(time==as.Date('2023-04-17')) %&gt;% .$temp\n\n\n\n1.2 Add column(s)\ndplyr::mutate(): add one or multiple columns to dataframe.\ne.g., add columnYear to df, its value is '2023'.\n\n# result is not save\ndf %&gt;% dplyr::mutate(Year=\"2023\") \ndf\n# result is saved\ndf$Year &lt;- \"2023\"\ndf[['Year']] &lt;- \"2023\"\ndf\n\n\n\n\n\n\n\nNote\n\n\n\nHow to save result using %&gt;%? Check example with ?mutate.\n\n\n\n\n1.3 Combine dataframes by column.\n\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\n                 temp=c(20,15,13), \n                 thermal_time=cumsum(c(20,15,13)))\n# with same length dataframe\near_df &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\n                     ear_weight=c(20,40,50))\nmerge(df,ear_df,by=\"time\")\ndplyr::left_join(df,ear_df,by=\"time\")\n# combind with vector of same length \ncbind(df, ear_weight=c(20,40,50))\ndf$ear_weight &lt;- c(20,40)\n\n# with differnt length \nshort_ear_df &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,2,1),\n                           ear_weight=c(20,40))\nmerge(df,short_ear_df,by=\"time\")\ndplyr::left_join(df,short_ear_df,by=\"time\")\n\n# combind with vector of different length \ncbind(df, ear_weight=c(20,40))\ndf$ear_weight &lt;- c(20,40)\n\n\n\n\n\n\n\nNote\n\n\n\nCheck description of merge and left_join, how are they different from each other? What happen if you remove the argument by?"
  },
  {
    "objectID": "posts/Week3/index.html#recommendation",
    "href": "posts/Week3/index.html#recommendation",
    "title": "Week3: Spikelet development",
    "section": "3 Recommendation",
    "text": "3 Recommendation\n\n3.1 online tutorials:\nggplot datacamp ggplot 2 ggplot gallery\n\n\n3.2 online books:\nggplot cheatsheet Data visualization with R R for Data Science: Chapter3 Visualization"
  },
  {
    "objectID": "posts/Week3/index.html#recommendation-online-books",
    "href": "posts/Week3/index.html#recommendation-online-books",
    "title": "Week3: Spikelet development",
    "section": "8 Recommendation online books",
    "text": "8 Recommendation online books\nData visualization with R R for Data Science: Chapter3 Visualization"
  },
  {
    "objectID": "posts/Week3/index.html#ggplot2",
    "href": "posts/Week3/index.html#ggplot2",
    "title": "Week3: dataframe and ggplot2",
    "section": "2 GGplot2",
    "text": "2 GGplot2\n\n2.1 ggplot grammar: layer-wise commands\n\n\n\nlayers of ggplot: click picture for original source\n\n\n\n\n\nsymbol, aes & …\n\n\nTop layer ggplot()and sub-layers sublayer commands 3, they are separated by +.3 see function reference for more!\nWithin each layer, there may be an aesthetic function aes() to set aesthetic setting like x,y and color,fill or shape. Function ggplot() will not generate any graph but used for setting common aesthetic setting across the sub-layer. Plot type are specify in sub-layer with prefix geom_xx.\n\n\n\n\n\n\norder matters!\n\n\n\nIf there are conflicts between the sub-layer commands, the latter will overwrite the previous one!\n\n\n\n\n2.2 Requirements of scientific plot.\n\naxis title: specify with unit if there is any using xlab() or ylab().\nlegend title: full name instead of default abbreviation using guides().\nother important rules: 4.\n\n4 Ten simple rules for better figures How to Make Good Graphs and Figures for Scientific Papers\n# Watch out the names!\nlibrary(ggplot)\nlibrary(ggplot2)\n\n\n\n\n\n\n\nNote\n\n\n\ngo to HU-box download ear_summarized.csvand put it in folder data. read this file using read.csv with relative path and named it as data\n\n\n\ndata %&gt;% \n  ggplot(aes(x=date,y=weight,color=var))+\n  geom_point()+\n  geom_line(aes(group=group))+ # link the point by group.\n  xlab(\"date of harvest\")+ #x axis title\n  ylab(\"ear weight(g)\")+   #y axis title\n  guides(color=guide_legend(title=\"Cultivar\")) #change legend title \n\n\n\n\nFigure 1: Growth of ear weight over time.\n\n\n\n\n\n\n\n\n\n\nchallenge : use theme_xx() function series to change background of the plot. Click for example.\n\n\n\n\n\n\n\n\n\n\nFigure 2: dark theme example.\n\n\n\n\n\n\n\n\n\n2.3 facet: organized subplot by column\nThere are two commonly used functionfacet_grid and facet_wrap. In side each function, subplots are arranged in the manner of (row ~ column). There could be multiple column names put in the row or column position.\n\n\n\n\n\n\nNote\n\n\n\ngo to HU-box download phenology_short.csvand put it in folder data. read this file using read.csv with relative path and named it as phenology\n\n\n\nphenology %&gt;% \nggplot(.,aes(x=var,y=value))+\n  geom_boxplot()+\n  facet_grid(Year~stage)\n\n\n\n\nFigure 3: uggly example.\n\n\n\n\n\n\n\n\n\n\nMake this graph more beautiful!\n\n\n\n\n\nHow to make each point show in box plot? (search for scatter points in boxplot ggplot2)\nHow does color and fill differs? Can you color it by var?\nCould you apply another color scale using viridis package?\nHow to remove the background of the facet title with theme()? what does element_blank() do?\nFollow up question, if you also apply theme_test() to it, it should be before or after theme()?\nHow to change title size? how does it related to element_text()\nCould you change the axis title display angle as 90 degree?\nHow do you add title?\n\n\n\n\n\nFigure 4: beautiful example."
  },
  {
    "objectID": "posts/Week3/index.html#spikelet-position-practice",
    "href": "posts/Week3/index.html#spikelet-position-practice",
    "title": "Week3: Spikelet development",
    "section": "3 Spikelet position practice",
    "text": "3 Spikelet position practice\n\n3.1 Data overview\n\ndat <-read.csv('./data/kernel_combine.csv',\n               header = T,stringsAsFactors = F) %>%\n  dplyr::filter(tiller==\"M\")\nglimpse(dat)\ndat %>% \n  group_by(car,var,nitrogen,time,rep) %>% \n  distinct()\n\n\n\n3.2 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\ndat %<>%\n  group_by(car,var,nitrogen,time,rep) %>% \n  mutate(type=cut(spike,3) %>% as.numeric(),\n         type=case_when(type==1~\"basal\",\n                        type==2~\"central\",\n                        T~\"apical\")) %>% \n  group_by(car,var,nitrogen,time,rep,type) %>% \n  dplyr::arrange(spike) %>% \n  mutate(Fl=seq(1,n())) %>% \n  dplyr::arrange(var,nitrogen,time,rep,spike)\nglimpse(dat)\n\nRows: 4,749\nColumns: 13\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          <int> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ~\n$ nitrogen     <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1~\n$ time         <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Al~\n$ rep          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, ~\n$ tiller       <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1,~\n$ flower       <int> 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 2, 2, ~\n$ kernel.full  <int> 0, 0, 1, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 2, 1, 2, 0, 0, 0, ~\n$ kernel.half  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         <chr> \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ce~\n$ Fl           <int> 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, ~"
  },
  {
    "objectID": "posts/Week3/index.html#recommendations",
    "href": "posts/Week3/index.html#recommendations",
    "title": "Week3: dataframe and ggplot2",
    "section": "3 Recommendations",
    "text": "3 Recommendations\n\n3.1 online tutorials:\nggplot datacamp ggplot 2 ggplot gallery\n\n\n3.2 online books:\nggplot cheatsheet Data visualization with R R for Data Science: Chapter3 Visualization\n\n\n\n\n\n\n\nFigure 5: original article."
  },
  {
    "objectID": "posts/Week3/index.html#feedback-this-week",
    "href": "posts/Week3/index.html#feedback-this-week",
    "title": "Week3: dataframe and ggplot2",
    "section": "4 Feedback this week",
    "text": "4 Feedback this week\nAnonymous feedback"
  },
  {
    "objectID": "posts/Week4/index.html",
    "href": "posts/Week4/index.html",
    "title": "Week4: column and row operations in dataframe",
    "section": "",
    "text": "Welcome to the fourth course! You will learn dataframe wrangling:"
  },
  {
    "objectID": "posts/Week4/index.html#dd",
    "href": "posts/Week4/index.html#dd",
    "title": "Week4: Grain development",
    "section": "1 dd",
    "text": "1 dd"
  },
  {
    "objectID": "sylabus.html",
    "href": "sylabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "penguin_table %&gt;% as_raw_html()\n\n\n\n  \n  \n  \n    \n      Penguins in the Palmer Archipelago\n    \n    \n      Data is courtesy of the {palmerpenguins} R package\n    \n    \n      \n      \n        Adelie\n      \n      \n        Chinstrap\n      \n      \n        Gentoo\n      \n    \n    \n      Female\n      Male\n      Female\n      Male\n      Female\n      Male\n    \n  \n  \n    \n      Island: Biscoe\n    \n    2007\n5\n5\n-\n-\n16\n17\n    2008\n9\n9\n-\n-\n22\n23\n    2009\n8\n8\n-\n-\n20\n21\n    \n      Island: Dream\n    \n    2007\n9\n10\n13\n13\n-\n-\n    2008\n8\n8\n9\n9\n-\n-\n    2009\n10\n10\n12\n12\n-\n-\n    \n      Island: Torgersen\n    \n    2007\n8\n7\n-\n-\n-\n-\n    2008\n8\n8\n-\n-\n-\n-\n    2009\n8\n8\n-\n-\n-\n-"
  },
  {
    "objectID": "posts/Week4/index.html#section",
    "href": "posts/Week4/index.html#section",
    "title": "Week4: Grain development",
    "section": "1 ",
    "text": "1"
  },
  {
    "objectID": "posts/Week4/index.html#spikelet-position-practice",
    "href": "posts/Week4/index.html#spikelet-position-practice",
    "title": "Week4: Grain development",
    "section": "3 Spikelet position practice",
    "text": "3 Spikelet position practice\nread kernel_combine.csv in folder data using relative path. subset column tiller which match pattern M.\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nchallenge\n\n\n\n\n\n\n\n# A tibble: 48 x 4\n# Groups:   car, var, nitrogen [48]\n     car var       nitrogen time \n   <int> <chr>     <chr>    <chr>\n 1     1 Alves     n3       t1   \n 2     1 Apertus   n3       t1   \n 3     1 Esket     n3       t1   \n 4     1 Pioneer   n3       t1   \n 5     1 Potential n3       t1   \n 6     1 Torrid    n3       t1   \n 7     2 Alves     n4       t1   \n 8     2 Apertus   n4       t1   \n 9     2 Esket     n4       t1   \n10     2 Pioneer   n4       t1   \n# i 38 more rows\n\n\n\n\n\n\n3.1 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\n\n\n\n\n3.2 basic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number\nfr: filling rate\nfc: potential filling rate\n\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\n3.3 Data wrangling and plot with facet"
  },
  {
    "objectID": "posts/Week4/index.html#lookuptable-of-treatment-not-yet",
    "href": "posts/Week4/index.html#lookuptable-of-treatment-not-yet",
    "title": "Week4: Grain development",
    "section": "4 lookuptable of treatment (not yet)",
    "text": "4 lookuptable of treatment (not yet)"
  },
  {
    "objectID": "posts/Week4/index.html#basic-summary-of-kernel-development-summ-for-single-spike",
    "href": "posts/Week4/index.html#basic-summary-of-kernel-development-summ-for-single-spike",
    "title": "Week4: Grain development",
    "section": "4 basic summary of kernel development summ for single spike",
    "text": "4 basic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number\nfr: filling rate\nfc: potential filling rate\n\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~"
  },
  {
    "objectID": "posts/Week4/index.html#data-wrangling-and-plot-with-facet",
    "href": "posts/Week4/index.html#data-wrangling-and-plot-with-facet",
    "title": "Week4: Grain development",
    "section": "5 Data wrangling and plot with facet",
    "text": "5 Data wrangling and plot with facet"
  },
  {
    "objectID": "docs/posts/Week4/index.html",
    "href": "docs/posts/Week4/index.html",
    "title": "BSC_project_IPFS2023",
    "section": "",
    "text": "Week4: Grain development\nTien-Cheng\n5/9/23\nWelcome to the third course! You will learn ggplot and dataframe wrangling:\n\nLearning goals\n\ndata frame wrangling with dplyr\nggplot2\n\n\nReview game Kahoot!"
  },
  {
    "objectID": "posts/Week4/index.html#more-mutate-examples",
    "href": "posts/Week4/index.html#more-mutate-examples",
    "title": "Week4: column and row operations in dataframe",
    "section": "1 more mutate examples",
    "text": "1 more mutate examples\nCreate a dataframe\n\ndf &lt;- expand.grid(x=letters[1:4],\n                  y=1:2)\n\n\n1.1 combine columns\npaste, interaction , unite Compare the results\n\ndf%&gt;% mutate(paste(x,y))\ndf%&gt;% mutate(z=paste(x,y))\ndf%&gt;% mutate(z=paste(x,y,sep = \"-\"))\ndf %&gt;% tidyr::unite(data = .,col = \"z\",c(x,y))\ndf &lt;- df %&gt;% mutate(z=interaction(x,y))\n\n\n\n1.2 add columns\n\n# add identifier based on row numbers\ndf %&gt;% mutate(id=1:n())\ndf %&gt;% mutate(id=1:nrow(.))\n# row names\nrownames(df)\nrownames(df) &lt;- LETTERS[1:nrow(df)]\nrownames(df)\n\n\n1.2.1 practice\nsubset the row where (x equals to “a”, y equals to 1) or (x equals to “c”, y equals to 2)\n\nHow many ways to achieve this? you can use dplyr::filter or [].\nObserve the row names, are they the same before and after subseting?\n\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\ndf %&gt;% filter(z%in%c(\"a.1\",\"c.2\"))\ndf %&gt;% filter((x==\"a\"&y==1)|(x==\"c\"&y==2))\ndf %&gt;% .[rownames(.)%in%c(\"A\",\"G\"),]\ndf %&gt;% with(.,.[(x==\"a\"&y==1)|(x==\"c\"&y==2),])"
  },
  {
    "objectID": "posts/Week4/index.html#conclude-your-dataframe-by-groups",
    "href": "posts/Week4/index.html#conclude-your-dataframe-by-groups",
    "title": "Week4: Grain development",
    "section": "2 Conclude your dataframe by groups",
    "text": "2 Conclude your dataframe by groups\n\n\n2.1 group_by\nLearn from examples!\n\n\n\n\n\n\npractice\n\n\n\n\nread climate.csv from data folder using relative path\nfind the sowing date (i.e., the first date) for each year (DFG_year) and each sowing treatment(sowing_date).\ncalculate thermal time based on DailyMean_Temperature\n\n\n\n\n\n2.2 how to get the minimum unique combination of dataframe?\nhow many unique year-months combinations were included in `climate 2019 for early and late sowing?\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  group_by(y,m) %>% \n  summarise()\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  dplyr::select(y,m) %>% \n  dplyr::distinct()\n\n\n\n2.3 wide to long\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \nclimate_long%>% \n  names()\n\n [1] \"DayTime\"           \"y\"                 \"m\"                \n [4] \"d\"                 \"Acc_Temperature\"   \"Acc_Percipitation\"\n [7] \"Acc_Radiation\"     \"sowing_date\"       \"DFG_year\"         \n[10] \"Daily_Terms\"       \"Daily_value\"      \n\n\n\n\n2.4 long to wide\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\"))\nclimate_long%>% \n  tidyr::pivot_wider(names_from = \"Daily_Terms\",\n                     values_from = \"Daily_value\")%>% \n  names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"Acc_Temperature\"        \"Acc_Percipitation\"     \n [7] \"Acc_Radiation\"          \"sowing_date\"            \"DFG_year\"              \n[10] \"DailyMean_Temperature\"  \"DailySum_Percipitation\" \"DailySum_Radiation\""
  },
  {
    "objectID": "posts/Week5/index.html",
    "href": "posts/Week5/index.html",
    "title": "Week5: pattern matching in dataframe",
    "section": "",
    "text": "Welcome to the fifth course! You will learn more about dataframe wrangling:"
  },
  {
    "objectID": "posts/Week5/index.html#more-mutate-examples",
    "href": "posts/Week5/index.html#more-mutate-examples",
    "title": "Week5: pattern matching in dataframe",
    "section": "2 more mutate examples",
    "text": "2 more mutate examples\nLast week’s practice.\n\ndf &lt;- expand.grid(x=letters[1:4],\n                  y=1:2)%&gt;%\n  # combine columns x and y \n  mutate(z=interaction(x,y))\nrownames(df) &lt;- LETTERS[1:nrow(df)]\n\n\n2.1 replace column\n\n2.1.1 replace one column based on single condition\n\ndf %&gt;% mutate(k=ifelse(x==\"a\",\"A\",\"B\"))\ndf %&gt;% mutate(k=ifelse(y==1,\"A\",\"B\"))\ndf %&gt;% mutate(k=case_when(x==\"a\"~\"A\",\n                          TRUE~\"B\"))\n\n\n\n\n\n\n\npractice\n\n\n\nMatching multiple conditions\nadd column k to df, when the condition x equals “a” and y equals 1. if TRUE return ‘A’, else return ‘B’.\n\n\n\n\n2.1.2 replace one column based on multiple conditions\nin case_when syntax, TRUE before ~ stands for the else conditions.\n\ndf %&gt;% mutate(k=case_when(x==\"a\"~\"A\",\n                          x==\"b\"~\"B\",\n                          TRUE~\"C\"))\n\n\n\n2.1.3 Look up table\n\nlook_table &lt;- data.frame(x=letters,\n                         X=LETTERS)\ndf %&gt;% merge(look_table)\n\n  x y   z X\n1 a 1 a.1 A\n2 a 2 a.2 A\n3 b 1 b.1 B\n4 b 2 b.2 B\n5 c 1 c.1 C\n6 c 2 c.2 C\n7 d 1 d.1 D\n8 d 2 d.2 D\n\n\n\n\n\n\n\n\npractice\n\n\n\nmerge is not actually replace the original column.\nWrite a function to replace letters with LETTERS. The input is a vector of lower case vector vec &lt;- c(\"c\",\"a\",\"b\",\"d\"), output will be the matched upper case vector c(\"C\",\"A\",\"B\",\"D\").\nHint: check function match() !!Before you start to write the code, please first write down the possible steps in text.!!"
  },
  {
    "objectID": "posts/Week5/index.html#matching-multiple-conditions",
    "href": "posts/Week5/index.html#matching-multiple-conditions",
    "title": "Week5: Grain development II",
    "section": "2 Matching multiple conditions",
    "text": "2 Matching multiple conditions\nadd column k to df, when the condition x equals “a” and y equals 1."
  },
  {
    "objectID": "posts/Week5/index.html#conclude-your-dataframe-by-groups",
    "href": "posts/Week5/index.html#conclude-your-dataframe-by-groups",
    "title": "Week5: Grain development II",
    "section": "Conclude your dataframe by groups",
    "text": "Conclude your dataframe by groups\n\n\ngroup_by()\nLearn from examples!\n\n\n\n\n\n\npractice\n\n\n\n\nread climate.csv from data folder using relative path\nfind the sowing date (i.e., the first date) for each year (DFG_year) and each sowing treatment(sowing_date).\ncalculate thermal time based on DailyMean_Temperature\n\n\n\n\n\nhow to get the minimum unique combination of dataframe?\nhow many unique year-months combinations were included in `climate 2019 for early and late sowing?\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  group_by(y,m) %>% \n  summarise()\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  dplyr::select(y,m) %>% \n  dplyr::distinct()\n\n\n\nwide to long\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \nclimate_long%>% \n  names()\n\n [1] \"DayTime\"           \"y\"                 \"m\"                \n [4] \"d\"                 \"Acc_Temperature\"   \"Acc_Percipitation\"\n [7] \"Acc_Radiation\"     \"sowing_date\"       \"DFG_year\"         \n[10] \"Daily_Terms\"       \"Daily_value\"      \n\n\n\n\nlong to wide\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\"))\nclimate_long%>% \n  tidyr::pivot_wider(names_from = \"Daily_Terms\",\n                     values_from = \"Daily_value\")%>% \n  names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"Acc_Temperature\"        \"Acc_Percipitation\"     \n [7] \"Acc_Radiation\"          \"sowing_date\"            \"DFG_year\"              \n[10] \"DailyMean_Temperature\"  \"DailySum_Percipitation\" \"DailySum_Radiation\""
  },
  {
    "objectID": "posts/Week5/index.html#spikelet-position-practice",
    "href": "posts/Week5/index.html#spikelet-position-practice",
    "title": "Week5: Grain development II",
    "section": "Spikelet position practice",
    "text": "Spikelet position practice\n\nread real data\nread kernel_combine.csv in folder data using relative path. subset column tiller which match pattern M.\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nchallenge\n\n\n\n\n\n\ndat %>% \n  group_by(car,var,nitrogen,time) %>% \n  summarise()\n\n\n\n\n\n\nread your own data\nGo to HU-box, download the student folder.\n\n\n\n\n\n\nPractice\n\n\n\n\nlist the file name in the folder using relative path\nread the file based on the name listed.\nadd a column containing student name information\ncombined the result in one\n\n\n\n\n\n\n\n\n\nPractice\n\n\n\n\ndo data summary for each file, compare the range of three files.\nVisualize it with ggplot, differentiate the data from each student by color.\n\n\n\n\n\nclassify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\n\n\n\n\nbasic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number\nfr: filling rate\nfc: potential filling rate\n\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\nData wrangling and plot with facet"
  },
  {
    "objectID": "posts/Week5/index.html#for-loop",
    "href": "posts/Week5/index.html#for-loop",
    "title": "Week5: Grain development II",
    "section": "For loop",
    "text": "For loop\nuse for loop for repetitive tasks.\n\nfilename <- c('grain_counting_practice_studentName1.xlsx',\n              'grain_counting_practice_studentName2.xlsx')\nfile_list<- filename %>% strsplit(\"_\")\n# tradition way of for loop\nres <- c()\nfor(i in 1:2){\n  res <- c(res,file_list[[i]][4])\n}\n\n# alternative in r package purrr\n# chr stands for the \"character\" output.\npurrr::map_chr(1:length(file_list),  ~{\n  file_list[[.x]][4]\n})\n\n# notice that the output of map_chr must be 1 element per iteration.\npurrr::map_chr(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\n# equivalent\npurrr::map(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\nlapply(filename,function(x){\n  x %>% strsplit(\"_\") %>% unlist()\n})\n\n\n\n\n\n\n\nchallenge\n\n\n\n\n\nUsing for loop, create a vector contained only the student name but replace the \".xlsx\" suffix. Search on google. What would be your keyword?"
  },
  {
    "objectID": "posts/Week6/index.html",
    "href": "posts/Week6/index.html",
    "title": "Week6: Grain development III",
    "section": "",
    "text": "Welcome to the sixth course! You will learn more about dataframe wrangling:\nTo match the pattern,how the order before or after %in% matters?\ndata.frame(x=letters) %&gt;% \n  filter(x%in%c('a','b'))\ndata.frame(x=letters) %&gt;% \n  filter(c('a','b')%in%x)\n\nc('a','b')%in%letters\nletters%in%c('a','b')"
  },
  {
    "objectID": "posts/Week6/index.html#conclude-your-dataframe-by-groups",
    "href": "posts/Week6/index.html#conclude-your-dataframe-by-groups",
    "title": "Week6: Grain development III",
    "section": "Conclude your dataframe by groups",
    "text": "Conclude your dataframe by groups\n\n\ngroup_by()\nLearn from examples!\n\n\n\n\n\n\npractice\n\n\n\n\nread climate.csv from data folder using relative path and name it as climate.\nfind the sowing date (i.e., the first date) for each year (DFG_year) and each sowing treatment(sowing_date) from .\n\n\nclimate_sub &lt;- climate %&gt;% \n  dplyr::select(DayTime,DailyMean_Temperature,DFG_year,sowing_date)\n\n\ncalculate thermal time based on DailyMean_Temperature from climate_sub\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nthermal_time &lt;- climate_sub%&gt;%\n  group_by(DFG_year,sowing_date) %&gt;% \n  mutate(DayTime=as.Date(DayTime,format=\"%Y-%m-%d\")) %&gt;% \n  arrange(DayTime) %&gt;% \n  mutate(ACC=cumsum(DailyMean_Temperature))\n\n\n# check with\nlibrary(ggplot2)\nmerge_thermal_time &lt;- thermal_time%&gt;% \n  merge(.,climate %&gt;% \n          select(DayTime,DFG_year,sowing_date,Acc_Temperature)) \n\nmerge_thermal_time %&gt;% \n  ggplot(.,aes(x=ACC,y=Acc_Temperature))+\n  geom_point(shape=0,size=.5,alpha=.5)+\n  geom_abline(intercept=0)+\n  facet_grid(sowing_date~DFG_year)"
  },
  {
    "objectID": "posts/Week6/index.html#for-loop",
    "href": "posts/Week6/index.html#for-loop",
    "title": "Week6: Grain development III",
    "section": "For loop",
    "text": "For loop\nuse for loop for repetitive tasks.\n\nfilename <- c('grain_counting_practice_studentName1.xlsx',\n              'grain_counting_practice_studentName2.xlsx')\nfile_list<- filename %>% strsplit(\"_\")\n# tradition way of for loop\nres <- c()\nfor(i in 1:2){\n  res <- c(res,file_list[[i]][4])\n}\n\n# alternative in r package purrr\n# chr stands for the \"character\" output.\npurrr::map_chr(1:length(file_list),  ~{\n  file_list[[.x]][4]\n})\n\n# notice that the output of map_chr must be 1 element per iteration.\npurrr::map_chr(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\n# equivalent\npurrr::map(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\nlapply(filename,function(x){\n  x %>% strsplit(\"_\") %>% unlist()\n})\n\n\nread your own data\nGo to HU-box, download the student folder.\n\n\n\n\n\n\nchallenge\n\n\n\nusing for loop, extract the student name from file name. 1. list the files of the folder student using list.files() 2. write your own for loop.\n\n\n$clement\n[1] \"Var\"          \"Plot_Id\"      \"Spikes\"       \"flower\"       \"kernal.full\" \n[6] \"Kernal.half\"  \"kernal.small\"\n\n$hanwenhsu\n[1] \"var\"          \"plot_id\"      \"spike\"        \"flower\"       \"kernel.full\" \n[6] \"kernel.half\"  \"kernel.small\"\n\n$shawon\n[1] \"var\"         \"plot.id\"     \"spike\"       \"flower\"      \"kernel.full\"\n[6] \"kernel.half\" \"NA.\"        \n\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\n\n\nUsing map_dfr(), read the three files in the folder.\n\nlist the files of the folder student using list.files()\nfind which function could read .xlsx\nread each .xlsx as one list element\nadd a column containing student name information\nuse for loop to return the column names of three dataframes.\nvisualize it with ggplot:\n\n6.1. do data summary for each file, compare the range of three files.\n6.2. Visualize it with ggplot, differentiate the data from each student by color."
  },
  {
    "objectID": "posts/Week6/index.html#spikelet-position-practice",
    "href": "posts/Week6/index.html#spikelet-position-practice",
    "title": "Week6: Grain development III",
    "section": "Spikelet position practice",
    "text": "Spikelet position practice\n\nread real data\nread kernel_combine.csv in folder data using relative path. subset column tiller which match pattern M.\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\ndat %>% \n  group_by(car,var,nitrogen,time) %>% \n  summarise()\n\n\n\n\n\n\nclassify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\n\n\n\n\nbasic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number\nfr: filling rate\nfc: potential filling rate\n\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\nData wrangling and plot with facet"
  },
  {
    "objectID": "posts/Week5/index.html#todays-discussion",
    "href": "posts/Week5/index.html#todays-discussion",
    "title": "Week5: pattern matching in dataframe",
    "section": "1 Today’s discussion",
    "text": "1 Today’s discussion\nIs it possible to access the elements at different columns and rows?\n\ndf &lt;- data.frame(\n  x1=1:3,\n  x2=letters[1:3],\n  x3=c(\"2a\",\"2b\",\"2c\")\n)\n# or condition separate by |\ndf$x1==2|df$x3==\"2c\"\n\ndf %&gt;% filter(x1==2|x3==\"2c\")\ndf %&gt;% with(.,x1==2|x3==\"2c\")\n\n# when not specifying the comma, it will be treated like column\ndf %&gt;% with(.,.[x1==2|x3==\"2c\"])\n# specify the rows\ndf %&gt;% with(.,.[x1==2|x3==\"2c\",])"
  },
  {
    "objectID": "posts/Week6/index.html#looping-with-for-lapply-and-map",
    "href": "posts/Week6/index.html#looping-with-for-lapply-and-map",
    "title": "Week6: Grain development III",
    "section": "Looping with for(), lapply() and map()",
    "text": "Looping with for(), lapply() and map()\ndeal repetitive tasks with loops.[^1] [^1]: lapply vs for loop lapply vs purrr\n\nfilename <- c('grain_counting_practice_studentName1.xlsx',\n              'grain_counting_practice_studentName2.xlsx')\nfile_list<- filename %>% strsplit(\"_\")\n# tradition way of for loop\nres <- c()\nfor(i in 1:2){\n  res <- c(res,file_list[[i]][4])\n}\n\n# alternative in r package purrr\n# chr stands for the \"character\" output.\npurrr::map_chr(1:length(file_list),  ~{\n  file_list[[.x]][4]\n})\n\n# notice that the output of map_chr must be 1 element per iteration.\npurrr::map_chr(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\n# equivalent\npurrr::map(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\nlapply(filename,function(x){\n  x %>% strsplit(\"_\") %>% unlist()\n})\n\n\nread your own data\nGo to HU-box, download the student folder.\n\n\n\n\n\n\nchallenge\n\n\n\nusing for loop, extract the student name from file name. 1. list the files of the folder student using list.files() 2. write your own for loop.\n\n\n$clement\n[1] \"Var\"          \"Plot_Id\"      \"Spikes\"       \"flower\"       \"kernal.full\" \n[6] \"Kernal.half\"  \"kernal.small\"\n\n$hanwenhsu\n[1] \"var\"          \"plot_id\"      \"spike\"        \"flower\"       \"kernel.full\" \n[6] \"kernel.half\"  \"kernel.small\"\n\n$shawon\n[1] \"var\"         \"plot.id\"     \"spike\"       \"flower\"      \"kernel.full\"\n[6] \"kernel.half\" \"NA.\"        \n\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\n\n\nUsing map_dfr(), read the three files in the folder.\n\nlist the files of the folder student using list.files()\nfind which function could read .xlsx\nread each .xlsx as one list element\nadd a column containing student name information\nuse for loop to return the column names of three dataframes.\nvisualize it with ggplot:\n\n6.1. do data summary for each file, compare the range of three files.\n6.2. Visualize it with ggplot, differentiate the data from each student by color."
  },
  {
    "objectID": "posts/Week6/index.html#recommendation",
    "href": "posts/Week6/index.html#recommendation",
    "title": "Week6: Grain development III",
    "section": "recommendation",
    "text": "recommendation\npurrr"
  },
  {
    "objectID": "posts/Week7/index.html",
    "href": "posts/Week7/index.html",
    "title": "Week7: Grain development III",
    "section": "",
    "text": "Welcome to the seventh course! You will learn more about dataframe wrangling:"
  },
  {
    "objectID": "posts/Week7/index.html#looping-with-for-lapply-and-map",
    "href": "posts/Week7/index.html#looping-with-for-lapply-and-map",
    "title": "Week7: Grain development III",
    "section": "Looping with for(), lapply() and map()",
    "text": "Looping with for(), lapply() and map()\ndeal repetitive tasks with loops.22 lapply vs for loop\nlapply vs purrr\n\nfilename &lt;- c('grain_counting_practice_studentName1.xlsx',\n              'grain_counting_practice_studentName2.xlsx')\nfile_list&lt;- filename %&gt;% strsplit(\"_\")\n# tradition way of for loop\nres &lt;- c()\nfor(i in 1:2){\n  res &lt;- c(res,file_list[[i]][4])\n}\n\n# alternative in r package purrr\n# chr stands for the \"character\" output.\npurrr::map_chr(1:length(file_list),  ~{\n  file_list[[.x]][4]\n})\n\n# notice that the output of map_chr must be 1 element per iteration.\npurrr::map_chr(filename,  ~{\n  .x %&gt;% strsplit(\"_\") %&gt;% unlist()\n})\n\n# equivalent\npurrr::map(filename,  ~{\n  .x %&gt;% strsplit(\"_\") %&gt;% unlist()\n})\n\nlapply(filename,function(x){\n  x %&gt;% strsplit(\"_\") %&gt;% unlist()\n})\n\n\nread your own data\nGo to HU-box, download the student folder.\n\n\n\n\n\n\nchallenge\n\n\n\nusing for loop, extract the student name from file name. 1. list the files of the folder student using list.files() 2. write your own for loop. \n\n\n$clement\n[1] \"Var\"          \"Plot_Id\"      \"Spikes\"       \"flower\"       \"kernal.full\" \n[6] \"Kernal.half\"  \"kernal.small\"\n\n$hanwenhsu\n[1] \"var\"          \"plot_id\"      \"spike\"        \"flower\"       \"kernel.full\" \n[6] \"kernel.half\"  \"kernel.small\"\n\n$shawon\n[1] \"var\"         \"plot.id\"     \"spike\"       \"flower\"      \"kernel.full\"\n[6] \"kernel.half\" \"NA.\""
  },
  {
    "objectID": "posts/Week7/index.html#spikelet-position-practice",
    "href": "posts/Week7/index.html#spikelet-position-practice",
    "title": "Week7: Grain development III",
    "section": "Spikelet position practice",
    "text": "Spikelet position practice\n\nread real data\nread kernel_combine.csv in folder data using relative path. subset column tiller which match pattern M.\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\ndat %>% \n  group_by(car,var,nitrogen,time) %>% \n  summarise()\n\n\n\n\n\n\nclassify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\nbasal (third-fifth spikelet from the bottom)\ncentral (middle spikelets)\napical (third-fifth spikelet from the top) spikelets throughout the spike reference\n\n\n\n\n\n\nbasic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number\nfr: filling rate\nfc: potential filling rate\n\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\nData wrangling and plot with facet"
  },
  {
    "objectID": "posts/Week7/index.html#recommendation",
    "href": "posts/Week7/index.html#recommendation",
    "title": "Week7: Grain development III",
    "section": "recommendation",
    "text": "recommendation\npurrr"
  },
  {
    "objectID": "posts/Week7/index.html#logic-of-coding",
    "href": "posts/Week7/index.html#logic-of-coding",
    "title": "Week7: Grain development III",
    "section": "Logic of coding",
    "text": "Logic of coding\n\n\nCheck: examine the datatype of each column in your dataframe.\nDrafting: draw the draft of your desired output.\nTarget columns: identify which columns you would need to generate the output.\nSteps: write down the possible steps which required to generate the target columns.\n\n\n\n\n\n\n\nchallenge\n\n\n\nHere is a draft from coding logic step2. Please practice step 1, 3 & 4 with climate.csv. Finally, can you reproduce this figure?\n\n\n\n\n\nFigure 1: step2: Draft of target\n\n\n\n\n\n\n\n\n\n\n\n\nanswer for steps\n\n\n\n\n\n\ncheck the datatype of DayTime, make sure it is Date.\ngroup_byyear and sowing date, mutate a new column called DAS(Days after sowing).\nuse ggplot to visualize this dataframe with points and lines:\n\nx is DAS, y is Acc_Temperature, color is DFG_year and the points should be linked of same DFG_year and sowing_date.\nIs there additional columns required?\n\n\n\n\n\n\n\n\n\nanswer for code\n\n\n\n\n\n\nclimate %&gt;% \n  # dplyr::filter(DFG_year%in%c(\"DFG2019\",\"DFG2020\")) %&gt;% \n  group_by(DFG_year,sowing_date) %&gt;% \n  mutate(DayTime=as.Date(DayTime,format=\"%Y-%m-%d\"),\n         DAS=as.numeric(DayTime-min(DayTime))) %&gt;% \n  ggplot(aes(x=DAS,y=Acc_Temperature,color=DFG_year,\n             group=interaction(sowing_date,DFG_year)))+\n  # geom_point()+\n  geom_line(aes(linetype=sowing_date),linewidth=1)+\n  theme_bw()+\n  theme(legend.position = c(.1,.65))+\n  labs(x=\"Days after sowing\",y= \"Thermal sum (°Cd)\")+\n  guides(color=guide_legend(title=\"Year\"))\n\n\n\n\n\nhow to get the minimum unique combination of dataframe?\nhow many unique year-months combinations were included in `climate 2019 for early and late sowing?\n\nclimate %&gt;% \n  dplyr::filter(DFG_year==\"DFG2019\") %&gt;% \n  group_by(y,m) %&gt;% \n  summarise()\n\nclimate %&gt;% \n  dplyr::filter(DFG_year==\"DFG2019\") %&gt;% \n  dplyr::select(y,m) %&gt;% \n  dplyr::distinct()\n\n\n\n\n\n\n\nchallenge\n\n\n\nread ear_summarized.csv and extract the unique combinations of nitrogen, appl and timeid\n\n\n  nitrogen     appl timeid\n1      176 Combined  Early\n2      176 Combined   Late\n3      176    Split  Early\n4      176    Split   Late\n5      220 Combined  Early\n6      220 Combined   Late\n7      220    Split  Early\n8      220    Split   Late"
  },
  {
    "objectID": "posts/Week7/index.html#shape-of-dataframe.",
    "href": "posts/Week7/index.html#shape-of-dataframe.",
    "title": "Week7: Grain development III",
    "section": "Shape of dataframe.",
    "text": "Shape of dataframe.\n\nIn general, we can describe the shape of dataframe as wide or long.\n\nWide refers to a dataframe which each column is one trait.\nLong refers to a dataframe which multiple trait names in one column and multiple trait values in another one. Since the values are concentrated in one column, this shape of dataframe is suitable for unifying operation.\n\n\nRelationship of shape of dataframe and data processing\nwide mutate() is designed for column-wise calculation.\n\nacross() provide quick access to multiple columns, could be useful for wide format. long.\nfacet_grid() will required a column which stores the grouping information for facet. This is can be achieved via the long format.\n\n\n\nwide to long\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \nclimate_long%>% \n  names()\n\n [1] \"DayTime\"           \"y\"                 \"m\"                \n [4] \"d\"                 \"Acc_Temperature\"   \"Acc_Percipitation\"\n [7] \"Acc_Radiation\"     \"sowing_date\"       \"DFG_year\"         \n[10] \"Daily_Terms\"       \"Daily_value\"      \n\n#select cols by position\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Terms\",\n                      values_to = \"value\",\n                      # select both patterns\n                      cols = grep(\"(Daily|Acc)\",names(.)))\n\ngrep(\"(Daily|Acc)\",names(climate))\n\n[1]  5  6  7  8  9 10\n\nclimate_long%>% \n  names()\n\n[1] \"DayTime\"     \"y\"           \"m\"           \"d\"           \"sowing_date\"\n[6] \"DFG_year\"    \"Terms\"       \"value\"      \n\n\n\n\nlong to wide\n\nclimate %>%names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"DailyMean_Temperature\"  \"Acc_Temperature\"       \n [7] \"Acc_Percipitation\"      \"Acc_Radiation\"          \"DailySum_Percipitation\"\n[10] \"DailySum_Radiation\"     \"sowing_date\"            \"DFG_year\"              \n\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\"))\nclimate_long%>% \n  tidyr::pivot_wider(names_from = \"Daily_Terms\",\n                     values_from = \"Daily_value\")%>% \n  names()\n\n [1] \"DayTime\"                \"y\"                      \"m\"                     \n [4] \"d\"                      \"Acc_Temperature\"        \"Acc_Percipitation\"     \n [7] \"Acc_Radiation\"          \"sowing_date\"            \"DFG_year\"              \n[10] \"DailyMean_Temperature\"  \"DailySum_Percipitation\" \"DailySum_Radiation\"    \n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nwide refers to one column one trait and long denotes the stacked traits in two columns (names and values).\n\nFrom select and filter point of view, when is wide format useful and when is long ideal?\nIf you want to mutate a column based on calculation between multiple traits, e.g., trait1-trait2/trait3, then which formats is more suitable?"
  },
  {
    "objectID": "posts/Week7/index.html#shapes-of-dataframe.",
    "href": "posts/Week7/index.html#shapes-of-dataframe.",
    "title": "Week7: Grain development III",
    "section": "Shapes of dataframe.",
    "text": "Shapes of dataframe.\n\nIn general, we can describe the shape of dataframe as wide or long.11 tidyr cheatsheet tidyr example\n\nWide refers to a dataframe which each column is one trait.\nLong refers to a dataframe which multiple trait names in one column and multiple trait values in another one.\n\n\nRelationship of shape of dataframe and data processing\nmutate() is designed for column-wise calculation.\nwide format:\n\nacross() provide quick access to multiple columns, could be useful for wide format.\n\nlong format:\n\nSince the values are concentrated in one column, this format is suitable for unifying operation.\nfacet_grid() will required a column which stores the grouping information for facet. This is can be achieved via the long format.\n\n\n\nwide to long\nIn the following examples, we want a unifying change\n\n# climate %&gt;%glimpse()\nclimate_long &lt;- climate %&gt;% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \n# climate_long%&gt;%   names()\n\n#select cols by position\n# grep(\"(Daily|Acc)\",names(climate))\nclimate_long &lt;- climate %&gt;% \n  tidyr::pivot_longer(names_to = \"Terms\",\n                      values_to = \"value\",\n                      # select both patterns\n                      cols = grep(\"(Daily|Acc)\",names(.)))\n\n# climate_long%&gt;% names()\n\n## data processing example\nclimate_long_subset&lt;- climate_long %&gt;% \n  filter(Terms%in%c('Acc_Temperature','Acc_Precipitation')) %&gt;% \n  group_by(DFG_year,sowing_date,Terms) %&gt;%\n  summarise(Value=mean(value))\n\nclimate_long_subset\n\n# A tibble: 6 x 4\n# Groups:   DFG_year, sowing_date [6]\n  DFG_year sowing_date Terms           Value\n  &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt;\n1 DFG2019  Early       Acc_Temperature  923.\n2 DFG2019  Late        Acc_Temperature  856.\n3 DFG2020  Early       Acc_Temperature 1002.\n4 DFG2020  Late        Acc_Temperature  910.\n5 DFG2021  Early       Acc_Temperature  928.\n6 DFG2021  Late        Acc_Temperature  799.\n\n#Fig 2\nlibrary(scales) %&gt;% suppressMessages()\n\nclimate_long %&gt;% \n  filter(Terms%in%c('Acc_Temperature','Acc_Radiation'),\n         sowing_date=='Early') %&gt;% \n  group_by(DFG_year,sowing_date) %&gt;% \n  mutate(DayTime=as.Date(DayTime,format=\"%Y-%m-%d\"),\n         DAS=as.numeric(DayTime-min(DayTime))) %&gt;% \n  ggplot(aes(DAS,value,color=DFG_year))+\n  geom_line()+\n  facet_grid(~Terms)+\n  theme_test()+\n  theme(strip.background = element_blank(),\n        strip.text = element_text(size=14),\n        axis.text = element_text(size=14),\n        axis.title = element_text(size=14),\n        legend.position = c(.1,.1))+\n  scale_y_log10(\n    labels = label_number(scale_cut = cut_short_scale())\n  )+\n  xlab('Days after sowing')\n\n\n\n\nFigure 2: long format and facet\n\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\nAnalyze the code that generating Fig2.\nFigure out how it works by blocking one line at a time. add documentation for each line.\nWhich function need package scales?\n\n\n\n\nlong ↔︎ wide\nTheoretically, we can easzily switch between the forms. Are they really the same after transforming back?\n\n# long\nclimate_long &lt;- climate %&gt;% # climate is wide\n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \n# wide again\nclimate_wide&lt;- climate_long%&gt;% \n  tidyr::pivot_wider(names_from = \"Daily_Terms\",\n                     values_from = \"Daily_value\")\n\n# check if they are the same \nsetdiff(names(climate),names(climate_wide))\n\ncharacter(0)\n\nall.equal(climate,climate_wide)\n\n [1] \"Names: 8 string mismatches\"                                                            \n [2] \"Attributes: &lt; Component \\\"class\\\": Lengths (1, 3) differ (string compare on first 1) &gt;\"\n [3] \"Attributes: &lt; Component \\\"class\\\": 1 string mismatch &gt;\"                                \n [4] \"Component 5: Mean relative difference: 96.42546\"                                       \n [5] \"Component 6: Mean relative difference: 0.8220306\"                                      \n [6] \"Component 7: Mean relative difference: 1534.907\"                                       \n [7] \"Component 8: Modes: numeric, character\"                                                \n [8] \"Component 8: target is numeric, current is character\"                                  \n [9] \"Component 9: Modes: numeric, character\"                                                \n[10] \"Component 9: target is numeric, current is character\"                                  \n[11] \"Component 10: Mean relative difference: 0.9968243\"                                     \n[12] \"Component 11: Modes: character, numeric\"                                               \n[13] \"Component 11: target is character, current is numeric\"                                 \n[14] \"Component 12: Modes: character, numeric\"                                               \n[15] \"Component 12: target is character, current is numeric\"                                 \n\n# change the order of column\nall.equal(climate,climate_wide[,names(climate)])\n\n[1] \"Attributes: &lt; Component \\\"class\\\": Lengths (1, 3) differ (string compare on first 1) &gt;\"\n[2] \"Attributes: &lt; Component \\\"class\\\": 1 string mismatch &gt;\"                                \n\n# change the type\nall.equal(climate,climate_wide[,names(climate)]%&gt;% as.data.frame())\n\n[1] TRUE\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nwide refers to one column one trait and long denotes the stacked traits in two columns (names and values).\n\nFrom select and filter point of view, when is wide format useful and when is long ideal?\nIf you want to mutate a column based on calculation between multiple traits, e.g., DailyMean_Temperature-DailySum_Percipitation/DailySum_Radiation, then which format is more suitable? or is it both possible?"
  },
  {
    "objectID": "posts/Week8/index.html",
    "href": "posts/Week8/index.html",
    "title": "Week8: Grain development Iv",
    "section": "",
    "text": "Welcome to the eighth course! You will learn more about for-loop and data visualization:"
  },
  {
    "objectID": "posts/Week8/index.html#logic-of-coding",
    "href": "posts/Week8/index.html#logic-of-coding",
    "title": "Week7: Grain development III",
    "section": "Logic of coding",
    "text": "Logic of coding\n\n\nCheck: examine the datatype of each column in your dataframe.\nDrafting: draw the draft of your desired output.\nTarget columns: identify which columns you would need to generate the output.\nSteps: write down the possible steps which required to generate the target columns.\n\n\n\n\n\n\n\nchallenge\n\n\n\nHere is a draft from coding logic step2. Please practice step 1, 3 & 4 with climate.csv. Finally, can you reproduce this figure?\n\n\n\n\n\nFigure 1: step2: Draft of target\n\n\n\n\n\n\n\n\n\n\n\n\nanswer for steps\n\n\n\n\n\n\ncheck the datatype of DayTime, make sure it is Date.\ngroup_byyear and sowing date, mutate a new column called DAS(Days after sowing).\nuse ggplot to visualize this dataframe with points and lines:\n\nx is DAS, y is Acc_Temperature, color is DFG_year and the points should be linked of same DFG_year and sowing_date.\nIs there additional columns required?\n\n\n\n\n\n\n\n\n\nanswer for code\n\n\n\n\n\n\nclimate %>% \n  # dplyr::filter(DFG_year%in%c(\"DFG2019\",\"DFG2020\")) %>% \n  group_by(DFG_year,sowing_date) %>% \n  mutate(DayTime=as.Date(DayTime,format=\"%Y-%m-%d\"),\n         DAS=as.numeric(DayTime-min(DayTime))) %>% \n  ggplot(aes(x=DAS,y=Acc_Temperature,color=DFG_year,\n             group=interaction(sowing_date,DFG_year)))+\n  # geom_point()+\n  geom_line(aes(linetype=sowing_date),linewidth=1)+\n  theme_bw()+\n  theme(legend.position = c(.1,.65))+\n  labs(x=\"Days after sowing\",y= \"Thermal sum (°Cd)\")+\n  guides(color=guide_legend(title=\"Year\"))\n\n\n\n\n\nhow to get the minimum unique combination of dataframe?\nhow many unique year-months combinations were included in `climate 2019 for early and late sowing?\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  group_by(y,m) %>% \n  summarise()\n\nclimate %>% \n  dplyr::filter(DFG_year==\"DFG2019\") %>% \n  dplyr::select(y,m) %>% \n  dplyr::distinct()\n\n\n\n\n\n\n\nchallenge\n\n\n\nread ear_summarized.csv and extract the unique combinations of nitrogen, appl and timeid\n\n\n  nitrogen     appl timeid\n1      176 Combined  Early\n2      176 Combined   Late\n3      176    Split  Early\n4      176    Split   Late\n5      220 Combined  Early\n6      220 Combined   Late\n7      220    Split  Early\n8      220    Split   Late"
  },
  {
    "objectID": "posts/Week8/index.html#shapes-of-dataframe.",
    "href": "posts/Week8/index.html#shapes-of-dataframe.",
    "title": "Week7: Grain development III",
    "section": "Shapes of dataframe.",
    "text": "Shapes of dataframe.\n\nIn general, we can describe the shape of dataframe as wide or long.11 tidyr cheatsheet tidyr example\n\nWide refers to a dataframe which each column is one trait.\nLong refers to a dataframe which multiple trait names in one column and multiple trait values in another one.\n\n\nRelationship of shape of dataframe and data processing\nmutate() is designed for column-wise calculation.\nwide format:\n\nacross() provide quick access to multiple columns, could be useful for wide format.\n\nlong format:\n\nSince the values are concentrated in one column, this format is suitable for unifying operation.\nfacet_grid() will required a column which stores the grouping information for facet. This is can be achieved via the long format.\n\n\n\nwide to long\nIn the following examples, we want a unifying change\n\n# climate %>%glimpse()\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \n# climate_long%>%   names()\n\n#select cols by position\n# grep(\"(Daily|Acc)\",names(climate))\nclimate_long <- climate %>% \n  tidyr::pivot_longer(names_to = \"Terms\",\n                      values_to = \"value\",\n                      # select both patterns\n                      cols = grep(\"(Daily|Acc)\",names(.)))\n\n# climate_long%>% names()\n\n## data processing example\nclimate_long_subset<- climate_long %>% \n  filter(Terms%in%c('Acc_Temperature','Acc_Precipitation')) %>% \n  group_by(DFG_year,sowing_date,Terms) %>%\n  summarise(Value=mean(value))\n\nclimate_long_subset\n\n# A tibble: 6 x 4\n# Groups:   DFG_year, sowing_date [6]\n  DFG_year sowing_date Terms           Value\n  <chr>    <chr>       <chr>           <dbl>\n1 DFG2019  Early       Acc_Temperature  923.\n2 DFG2019  Late        Acc_Temperature  856.\n3 DFG2020  Early       Acc_Temperature 1002.\n4 DFG2020  Late        Acc_Temperature  910.\n5 DFG2021  Early       Acc_Temperature  928.\n6 DFG2021  Late        Acc_Temperature  799.\n\n#Fig 2\nlibrary(scales) %>% suppressMessages()\n\nclimate_long %>% \n  filter(Terms%in%c('Acc_Temperature','Acc_Radiation'),\n         sowing_date=='Early') %>% \n  group_by(DFG_year,sowing_date) %>% \n  mutate(DayTime=as.Date(DayTime,format=\"%Y-%m-%d\"),\n         DAS=as.numeric(DayTime-min(DayTime))) %>% \n  ggplot(aes(DAS,value,color=DFG_year))+\n  geom_line()+\n  facet_grid(~Terms)+\n  theme_test()+\n  theme(strip.background = element_blank(),\n        strip.text = element_text(size=14),\n        axis.text = element_text(size=14),\n        axis.title = element_text(size=14),\n        legend.position = c(.1,.1))+\n  scale_y_log10(\n    labels = label_number(scale_cut = cut_short_scale())\n  )+\n  xlab('Days after sowing')\n\n\n\n\nFigure 2: long format and facet\n\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\nAnalyze the code that generating Fig2.\nFigure out how it works by blocking one line at a time. add documentation for each line.\nWhich function need package scales?\n\n\n\n\nlong ↔︎ wide\nTheoretically, we can easzily switch between the forms. Are they really the same after transforming back?\n\n# long\nclimate_long <- climate %>% # climate is wide\n  tidyr::pivot_longer(names_to = \"Daily_Terms\",\n                      values_to = \"Daily_value\",\n                      cols = contains(\"Daily\")) \n# wide again\nclimate_wide<- climate_long%>% \n  tidyr::pivot_wider(names_from = \"Daily_Terms\",\n                     values_from = \"Daily_value\")\n\n# check if they are the same \nsetdiff(names(climate),names(climate_wide))\n\ncharacter(0)\n\nall.equal(climate,climate_wide)\n\n [1] \"Names: 8 string mismatches\"                                                            \n [2] \"Attributes: < Component \\\"class\\\": Lengths (1, 3) differ (string compare on first 1) >\"\n [3] \"Attributes: < Component \\\"class\\\": 1 string mismatch >\"                                \n [4] \"Component 5: Mean relative difference: 96.42546\"                                       \n [5] \"Component 6: Mean relative difference: 0.8220306\"                                      \n [6] \"Component 7: Mean relative difference: 1534.907\"                                       \n [7] \"Component 8: Modes: numeric, character\"                                                \n [8] \"Component 8: target is numeric, current is character\"                                  \n [9] \"Component 9: Modes: numeric, character\"                                                \n[10] \"Component 9: target is numeric, current is character\"                                  \n[11] \"Component 10: Mean relative difference: 0.9968243\"                                     \n[12] \"Component 11: Modes: character, numeric\"                                               \n[13] \"Component 11: target is character, current is numeric\"                                 \n[14] \"Component 12: Modes: character, numeric\"                                               \n[15] \"Component 12: target is character, current is numeric\"                                 \n\n# change the order of column\nall.equal(climate,climate_wide[,names(climate)])\n\n[1] \"Attributes: < Component \\\"class\\\": Lengths (1, 3) differ (string compare on first 1) >\"\n[2] \"Attributes: < Component \\\"class\\\": 1 string mismatch >\"                                \n\n# change the type\nall.equal(climate,climate_wide[,names(climate)]%>% as.data.frame())\n\n[1] TRUE\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nwide refers to one column one trait and long denotes the stacked traits in two columns (names and values).\n\nFrom select and filter point of view, when is wide format useful and when is long ideal?\nIf you want to mutate a column based on calculation between multiple traits, e.g., DailyMean_Temperature-DailySum_Percipitation/DailySum_Radiation, then which format is more suitable? or is it both possible?"
  },
  {
    "objectID": "posts/Week8/index.html#looping-with-for-lapply-and-map",
    "href": "posts/Week8/index.html#looping-with-for-lapply-and-map",
    "title": "Week7: Grain development III",
    "section": "Looping with for(), lapply() and map()",
    "text": "Looping with for(), lapply() and map()\ndeal repetitive tasks with loops.22 lapply vs for loop\nlapply vs purrr\n\nfilename <- c('grain_counting_practice_studentName1.xlsx',\n              'grain_counting_practice_studentName2.xlsx')\nfile_list<- filename %>% strsplit(\"_\")\n# tradition way of for loop\nres <- c()\nfor(i in 1:2){\n  res <- c(res,file_list[[i]][4])\n}\n\n# alternative in r package purrr\n# chr stands for the \"character\" output.\npurrr::map_chr(1:length(file_list),  ~{\n  file_list[[.x]][4]\n})\n\n# notice that the output of map_chr must be 1 element per iteration.\npurrr::map_chr(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\n# equivalent\npurrr::map(filename,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n})\n\nlapply(filename,function(x){\n  x %>% strsplit(\"_\") %>% unlist()\n})\n\n\nread your own data\nGo to HU-box, download the student folder.\n\n\n\n\n\n\nchallenge\n\n\n\nusing for loop, extract the student name from file name. 1. list the files of the folder student using list.files() 2. write your own for loop.\n\n\n$clement\n[1] \"Var\"          \"Plot_Id\"      \"Spikes\"       \"flower\"       \"kernal.full\" \n[6] \"Kernal.half\"  \"kernal.small\"\n\n$hanwenhsu\n[1] \"var\"          \"plot_id\"      \"spike\"        \"flower\"       \"kernel.full\" \n[6] \"kernel.half\"  \"kernel.small\"\n\n$shawon\n[1] \"var\"         \"plot.id\"     \"spike\"       \"flower\"      \"kernel.full\"\n[6] \"kernel.half\" \"NA.\"        \n\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\n\n\nUsing map_dfr(), read the three files in the folder.\n\nlist the files of the folder student using list.files()\nfind which function could read .xlsx\nread each .xlsx as one list element\nadd a column containing student name information\nuse for loop to return the column names of three dataframes.\nvisualize it with ggplot:\n\n6.1. do data summary for each file, compare the range of three files.\n6.2. Visualize it with ggplot, differentiate the data from each student by color."
  },
  {
    "objectID": "posts/Week8/index.html#spikelet-position-practice",
    "href": "posts/Week8/index.html#spikelet-position-practice",
    "title": "Week8: Grain development Iv",
    "section": "2 Spikelet position practice",
    "text": "2 Spikelet position practice\n\n2.1 read real data\nread kernel_combine.csv in folder data using relative path. subset column tiller which match pattern M.\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndat %>% \n  group_by(car,var,nitrogen,time) %>% \n  summarise()\n\n\n\n\n\n\n2.2 classify spikelet based on position\nsee Section 1.7 for definition.\n\n\nRows: 4,749\nColumns: 12\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ nitrogen     <chr> \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3~\n$ time         <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          <chr> \"Pioneer\", \"Alves\", \"Potential\", \"Torrid\", \"Torrid\", \"Alv~\n$ rep          <int> 1, 1, 1, 1, 2, 3, 1, 2, 3, 2, 5, 4, 4, 4, 5, 5, 5, 5, 5, ~\n$ tiller       <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ flower       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ~\n$ kernel.full  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.half  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         <chr> \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ba~\n\n\n\n\n2.3 basic summary of kernel development summ for single spike\nsee Section 1.9 for definition.\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\n2.4 Data wrangling and plot with facet\n\nstep1 create long format\n\n\ncreate long format long_format, combine nitrogen and time, names to “treatment” values to “levels”\nfor each rep,levels,type,var,spike,treatment calculate the maximum full kernel and name it fertile_flower.\nfor each levels,type,var,spike,treatment calculate the mean fertile_flower.\n\n\nstep2 visualize\n\n\nsubset the value of fertile_flowerless than 10\nbased on this graph, what is x, y, color and shape?\nwhat re the facet?"
  },
  {
    "objectID": "posts/Week8/index.html#recommendation",
    "href": "posts/Week8/index.html#recommendation",
    "title": "Week8: Grain development Iv",
    "section": "2 recommendation",
    "text": "2 recommendation\nAdvanced R: control flow"
  },
  {
    "objectID": "posts/Week8/index.html#challenge-how-to-name-list-elements-based-on-students-name",
    "href": "posts/Week8/index.html#challenge-how-to-name-list-elements-based-on-students-name",
    "title": "Week8: Grain development Iv",
    "section": "Challenge: how to name list elements based on student’s name ?",
    "text": "Challenge: how to name list elements based on student’s name ?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nstudent_name <-   purrr::map(filenames,  ~{\n  .x %>% strsplit(\"_\") %>% unlist()\n}) %>% map_chr(.,~{.x[4] %>% sub(\".xlsx\",\"\",.)})\n\nnames(df) <-student_name\ndf\n\n\n\n\n\nlibrary(magrittr)\ndf<- map_dfr(list.files(\"../data/student\"),~{\n  \n  student_name <-  .x %>% strsplit(\"_\") %>% unlist() %>% \n    .[4] %>% sub(\".xlsx\",\"\",.)\n  \n  file<- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1) %>%  \n    `colnames<-`(stringr::str_to_lower(names(.)))%>% \n    `colnames<-`(gsub(\"kernal\",\"kernel\",names(.))) %>% \n    `colnames<-`(gsub(\"spikes\",\"spike\",names(.)))%>%\n    `colnames<-`(gsub(\"plot.id\",\"plot_id\",names(.))) %>% \n    mutate(student=student_name)\n}) \ndf %<>% mutate(var=\"Capone\",plot_id=159) %>% \n  .[!grepl(\"na.\",names(.))]\ndf %>% \n  group_by(student,spike) %>% \n  ggplot(aes(flower,spike,color=student))+\n  geom_line()\n\n\n\ndf %>% \n  group_by(student,spike) %>% \n  ggplot(aes(flower,spike,color=student))+\n  geom_point()+\n  geom_path()+\n  facet_grid(~student)+\n  theme_bw()+\n  theme(strip.background = element_blank(),\n        legend.position = \"none\")\n\n\n\n# theme(legend.position = \"bottom\")\ndf %>% \n  pivot_longer(starts_with(\"kernel\"),\n               values_to = \"kernel\",\n               names_to=\"kerneltype\") %>% \n  group_by(student,spike) %>% \n  ggplot(aes(kernel,spike,color=student))+\n  geom_point()+\n  geom_path()+\n  facet_grid(kerneltype~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\nWarning: Removed 19 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values (`geom_path()`).\n\n\n\n\n\nFrom Student’s folder ::: {.callout-note collapse=“true”} ## challenge\nUsing map_dfr(), read the three files in the folder.\n\nlist the files of the folder student using list.files()\nfind which function could read .xlsx\nread each .xlsx as one list element\nadd a column containing student name information\nuse for loop to return the column names of three dataframes.\nvisualize it with ggplot:\n\n6.1. do data summary for each file, compare the range of three files.\n6.2. Visualize it with ggplot, differentiate the data from each student by color. :::"
  },
  {
    "objectID": "posts/Week8/index.html#students-data",
    "href": "posts/Week8/index.html#students-data",
    "title": "Week8: Grain development Iv",
    "section": "1 Student’s data",
    "text": "1 Student’s data\npractice with files from data/student.\n\n1.1 How to save the column names of all files in a directory to a list using for loop?\n\n\n\n\n\n\nFor loop concept\n\n\n\n\n\npath &lt;- \"./data/student/\"\nfilenames &lt;- list.files(path,pattern=\".xlsx\")\n#create empty list\ndf &lt;- vector(mode=\"list\",length=length(filenames))\n\nfor(i in 1:length(filenames)){\n  fullpath &lt;- paste0(path,filenames[i])\n  df[[i]] &lt;- xlsx::read.xlsx(fullpath,\n                             sheetIndex = 1) %&gt;% \n    names()\n}\n\ndf \n\n\n\n\n\n1.2 How to name list elements based on student’s name ?\n\n\n$clement\n[1] \"Var\"          \"Plot_Id\"      \"Spikes\"       \"flower\"       \"kernal.full\" \n[6] \"Kernal.half\"  \"kernal.small\"\n\n$hanwenhsu\n[1] \"var\"          \"plot_id\"      \"spike\"        \"flower\"       \"kernel.full\" \n[6] \"kernel.half\"  \"kernel.small\"\n\n$shawon\n[1] \"var\"         \"plot.id\"     \"spike\"       \"flower\"      \"kernel.full\"\n[6] \"kernel.half\" \"NA.\"        \n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nstudent_name &lt;-   purrr::map_chr(filenames,  ~{\n  .x %&gt;% strsplit(\"_\") %&gt;% unlist() %&gt;% \n    .[4] %&gt;% sub(\".xlsx\",\"\",.)\n}) \nnames(df) &lt;-student_name\ndf\n\n\n\n\n\n\n1.3 How to combine all the dataframe by row?\nIf you know the column names are different, can you still combine them?\n\ndf&lt;- map_dfr(list.files(\"../data/student\"),~{\n  \n  file&lt;- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1)\n})\ndf %&gt;% \n  glimpse()\n\nRows: 57\nColumns: 15\n$ Var          &lt;chr&gt; \"Capone\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ Plot_Id      &lt;dbl&gt; 159, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ Spikes       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\n$ flower       &lt;dbl&gt; 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, ~\n$ kernal.full  &lt;dbl&gt; 0, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, ~\n$ Kernal.half  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernal.small &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ var          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ plot_id      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ spike        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ kernel.full  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ kernel.half  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ kernel.small &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ plot.id      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ NA.          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n\n\nHere are possible steps:\n\n\n\n\n\n\n\nobserve the patterns of column names, how to unify the column names?\nreplace “kernal” with “kernel”\nreplace “spikes” with “spike”\nreplace “plot.id” with “plot_id”\nhow to add the student’s name as a column? where should you put it in the for-loop body?\nhow to fill the missing cultivar and plot_id?\nremove “na.” column check your loop-body with the first element in your range.\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nlibrary(magrittr)\ndf&lt;- map_dfr(list.files(\"../data/student\"),~{\n  \n  student_name &lt;-  .x %&gt;% strsplit(\"_\") %&gt;% unlist() %&gt;% \n    .[4] %&gt;% sub(\".xlsx\",\"\",.)\n  \n  file&lt;- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1) %&gt;%  \n    `colnames&lt;-`(stringr::str_to_lower(names(.)))%&gt;% \n    `colnames&lt;-`(gsub(\"kernal\",\"kernel\",names(.))) %&gt;% \n    `colnames&lt;-`(gsub(\"spikes\",\"spike\",names(.)))%&gt;%\n    `colnames&lt;-`(gsub(\"plot.id\",\"plot_id\",names(.))) %&gt;% \n    mutate(student=student_name)\n}) \ndf %&lt;&gt;% mutate(var=\"Capone\",plot_id=159) %&gt;% \n  .[!grepl(\"na.\",names(.))]\ndf %&gt;% glimpse()\n\nRows: 57\nColumns: 8\n$ var          &lt;chr&gt; \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone~\n$ plot_id      &lt;dbl&gt; 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 15~\n$ spike        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\n$ flower       &lt;dbl&gt; 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, ~\n$ kernel.full  &lt;dbl&gt; 0, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, ~\n$ kernel.half  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ student      &lt;chr&gt; \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"c~\n\n\nThis answer is written in map_() series, could you rewrite in for loop?\n\n\n\n\n\n1.4 How to visualize the result?\nPractice to make a draft, what will be the x and y, what will be the color?\nIs there difference between geom_line() and geom_path()?\n\n\n\n\n\n\nLine Plot 1\n\n\n\n\n\n\n\nLine Plot 2\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\n# line plot 1\ndf %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(flower,spike,color=student))+\n  geom_line(alpha=.5)+\n  theme(legend.position = \"bottom\")\n# line plot 2\ndf %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(flower,spike,color=student))+\n  geom_point()+\n  geom_path(alpha=.5)+\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/Week8/index.html#practice-on-a-larger-dataset",
    "href": "posts/Week8/index.html#practice-on-a-larger-dataset",
    "title": "Week8: Grain development Iv",
    "section": "2 Practice on a larger dataset",
    "text": "2 Practice on a larger dataset\n\nread kernel_combine.csv in folder data using relative path.\nsubset column tiller which match the pattern M.\n\n\n2.1 how to get overview of unique combinations?\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndat %>% \n  group_by(car,var,nitrogen,time) %>% \n  summarise()\n\n\n\n\n\n\n2.2 classify spikelet based on position\nsee Section 1.7 for definition.\n\n\nRows: 4,749\nColumns: 12\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ nitrogen     <chr> \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3~\n$ time         <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          <chr> \"Pioneer\", \"Alves\", \"Potential\", \"Torrid\", \"Torrid\", \"Alv~\n$ rep          <int> 1, 1, 1, 1, 2, 3, 1, 2, 3, 2, 5, 4, 4, 4, 5, 5, 5, 5, 5, ~\n$ tiller       <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ flower       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ~\n$ kernel.full  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.half  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         <chr> \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ba~\n\n\n\n\n2.3 basic summary of kernel development summ for single spike\nsee Section 1.9 for definition.\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen <chr> \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     <chr> \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      <chr> \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      <int> 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     <chr> \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       <int> 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      <int> 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       <int> 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       <int> 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       <dbl> 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\n2.4 Data wrangling and plot with facet\n\n\n\n\n\n\n\nstep1 create long format\n\n\ncreate long format long_format, combine nitrogen and time, names to “treatment” values to “levels”\nfor each rep,levels,type,var,spike,treatment calculate the maximum full kernel and name it fertile_flower.\nfor each levels,type,var,spike,treatment calculate the mean fertile_flower.\n\n\n\n\n\n\n\n\n\n\n\nstep2 visualize\n\n\nsubset the value of fertile_flowerless than 10\nbased on this graph, what is x, y, color and shape?\nwhat re the facet?"
  },
  {
    "objectID": "posts/Week9/index.html",
    "href": "posts/Week9/index.html",
    "title": "Week9: Grain development v",
    "section": "",
    "text": "Welcome to the nigth course! You will learn more aboutdata visualization:"
  },
  {
    "objectID": "posts/Week9/index.html#students-data",
    "href": "posts/Week9/index.html#students-data",
    "title": "Week9: Grain development v",
    "section": "1 Student’s data",
    "text": "1 Student’s data\npractice with files from data/student.\n\nlibrary(magrittr)\ndf&lt;- map_dfr(list.files(\"../data/student\"),~{\n  \n  student_name &lt;-  .x %&gt;% strsplit(\"_\") %&gt;% unlist() %&gt;% \n    .[4] %&gt;% sub(\".xlsx\",\"\",.)\n  \n  file&lt;- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1) %&gt;%  \n    `colnames&lt;-`(stringr::str_to_lower(names(.)))%&gt;% \n    `colnames&lt;-`(gsub(\"kernal\",\"kernel\",names(.))) %&gt;% \n    `colnames&lt;-`(gsub(\"spikes\",\"spike\",names(.)))%&gt;%\n    `colnames&lt;-`(gsub(\"plot.id\",\"plot_id\",names(.))) %&gt;% \n    mutate(student=student_name)\n}) \ndf %&lt;&gt;% mutate(var=\"Capone\",plot_id=159) %&gt;% \n  .[!grepl(\"na.\",names(.))]\ndf %&gt;% glimpse()\n\nRows: 57\nColumns: 8\n$ var          &lt;chr&gt; \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone~\n$ plot_id      &lt;dbl&gt; 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 15~\n$ spike        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\n$ flower       &lt;dbl&gt; 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, ~\n$ kernel.full  &lt;dbl&gt; 0, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, ~\n$ kernel.half  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ student      &lt;chr&gt; \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"c~\n\n\n\n1.1 How to make it a bit more beautiful?\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(flower,spike,color=student))+\n  geom_point()+\n  geom_path(alpha=.5)+\n  facet_grid(~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n1.2 How to place kernel-related traits in subplots?\n\n\n\n\n\n\npivot_longer()to collect kernel-related traits\nfacet_grid()\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  pivot_longer(starts_with(\"kernel\"),\n               values_to = \"kernel\",\n               names_to=\"kerneltype\") %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(kernel,spike,color=student))+\n  geom_point()+\n  geom_path()+\n  facet_grid(kerneltype~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n1.3 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\n\n\n\n\n\n\nbasal 1/3 spikelet from the bottom)\ncentral (middle 1/3 of spikelets)\napical (1/3 spikelets from the top)\n\nreference\n\n\n\ntry to clssify each spike into three classes based on their position.\n\n\n\n\n\n\nchallenge\n\n\n\n\nadd new column called type using mutate()\ncut() could be useful, which column you should apply to?\nwhat will you get when you pass the result of cut() to as.numeric()?\nuse case_when() to re-calssify the result of step 3.\nbased on which columns should you classify? what are your group columns for group_by?\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&lt;&gt;% \n  group_by(student,plot_id,var) %&gt;% \n  mutate(type=cut(spike,3) %&gt;% as.numeric(),\n         type=case_when(type==1~\"basal\",\n                        type==2~\"central\",\n                        T~\"apical\"))\n\n\n\n\ngo to Section 2.2 for more practices.\n\n\n\n\n\nHow to plot this half-box plot?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nlibrary(ggpol)\np &lt;- df%&gt;% \n  ggplot(aes(type,flower,fill=student))+\n  geom_boxjitter(aes(color=student),alpha=.4,\n                 jitter.shape = 21, jitter.color = NA, \n                 jitter.params = list(height = 0, width = 0.04),\n                 outlier.color = NA, errorbar.draw = TRUE)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"bottom\") \n\nprint(p)\n\n\n\n\n\n\n1.4 how to change the order of the box plot?\nset the type as factor and arrange the levels from basal to apical.\n\n\n\n\n\n\n\n1.5 summarize\n\n\n\n\n\n\nbasic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number (half+pull)\nfr: filling rate (full kernel/ floret number)\nfc: potential filling rate (potential kernel number/ floret number)\n\n\n\n\nsee also Section 2.3 for another example.\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nsum.df &lt;- df %&gt;% \n  dplyr::group_by(student,var,plot_id,type) %&gt;% \n  dplyr::summarise(\n    Sp=max(spike),#total spikelet\n    Fl=max(flower),# maximum floret \n    sfl=sum(flower),# total floret\n    kf=sum(kernel.full,na.rm = T),# total full kernel\n    kh=sum(kernel.half,na.rm = T),# total half kernel\n    ks=sum(kernel.small,na.rm = T),# total small kernel\n    kp=kf+kh,# potential kernel number \n    fr=kf/sfl,# filling rate \n    fc=kf/kp)#potential filling rate\n\n\n\n\n\n\n1.6 how to visualize the maximum full kernels per spikelet?\nFor each spike position, how many maximum full kernels can you have?\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf%&gt;% \n  group_by(student,var,plot_id,type,spike) %&gt;% \n  summarise(fertile_flower=max(kernel.full)) %&gt;% \n  ggplot(aes(fertile_flower,spike,color=type))+\n  geom_point()+\n  facet_grid(~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"bottom\")+\n  geom_path()"
  },
  {
    "objectID": "posts/Week9/index.html#practice-on-a-larger-dataset",
    "href": "posts/Week9/index.html#practice-on-a-larger-dataset",
    "title": "Week9: Grain development v",
    "section": "3 Practice on a larger dataset",
    "text": "3 Practice on a larger dataset\n\nread kernel_combine.csv in folder data using relative path.\nsubset column tiller which match the pattern M.\n\n\n3.1 how to get overview of unique combinations?\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndat %&gt;% \n  group_by(car,var,nitrogen,time) %&gt;% \n  summarise()\n\n\n\n\n\n\n3.2 classify spikelet based on position\nsee Section 2.3 for definition.\n\n\nRows: 4,749\nColumns: 12\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ nitrogen     &lt;chr&gt; \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3~\n$ time         &lt;chr&gt; \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          &lt;chr&gt; \"Pioneer\", \"Alves\", \"Potential\", \"Torrid\", \"Torrid\", \"Alv~\n$ rep          &lt;int&gt; 1, 1, 1, 1, 2, 3, 1, 2, 3, 2, 5, 4, 4, 4, 5, 5, 5, 5, 5, ~\n$ tiller       &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ flower       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ~\n$ kernel.full  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.half  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         &lt;chr&gt; \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ba~\n\n\n\n\n3.3 basic summary of kernel development summ for single spike\nsee Section 2.5 for definition.\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen &lt;chr&gt; \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     &lt;chr&gt; \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      &lt;chr&gt; \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      &lt;int&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     &lt;chr&gt; \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       &lt;int&gt; 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       &lt;int&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      &lt;int&gt; 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       &lt;int&gt; 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       &lt;int&gt; 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       &lt;int&gt; 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       &lt;dbl&gt; 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\n3.4 Data wrangling and plot with facet\n\n\n\n\n\n\n\nstep1 create long format\n\n\ncreate long format long_format, combine nitrogen and time, names to “treatment” values to “levels”\nfor each rep,levels,type,var,spike,treatment calculate the maximum full kernel and name it fertile_flower.\nfor each levels,type,var,spike,treatment calculate the mean fertile_flower.\n\n\n\n\n\n\n\n\n\n\n\nstep2 visualize\n\n\nsubset the value of fertile_flowerless than 10\nbased on this graph, what is x, y, color and shape?\nwhat re the facet?"
  },
  {
    "objectID": "posts/Week9/index.html#recommendation",
    "href": "posts/Week9/index.html#recommendation",
    "title": "Week9: Grain development v",
    "section": "3 recommendation",
    "text": "3 recommendation\nDatavisualization Scientific story telling"
  },
  {
    "objectID": "posts/Week9/index.html#story-telling-warm-up-for-final-presentation",
    "href": "posts/Week9/index.html#story-telling-warm-up-for-final-presentation",
    "title": "Week9: Grain development v",
    "section": "1 Story telling: Warm up for final Presentation",
    "text": "1 Story telling: Warm up for final Presentation\n\n\n\nFigure1: Project Plan\n\n\n\n\n\nFigure2: Story type\n\n\n\n\n\nFigure3: Cycle of visualization\n\n\n\n\n\nVisualization based on data type: click picture for source\n\n\n1 21 Ten simple rules for better figures2 How to Make Good Graphs and Figures for Scientific Papers"
  },
  {
    "objectID": "posts/Week9/index.html#exercise-with-students-data",
    "href": "posts/Week9/index.html#exercise-with-students-data",
    "title": "Week9: Grain development v",
    "section": "2 Exercise with student’s data",
    "text": "2 Exercise with student’s data\npractice with files from data/student.\n\nlibrary(magrittr)\ndf&lt;- map_dfr(list.files(\"../data/student\"),~{\n  \n  student_name &lt;-  .x %&gt;% strsplit(\"_\") %&gt;% unlist() %&gt;% \n    .[4] %&gt;% sub(\".xlsx\",\"\",.)\n  \n  file&lt;- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1) %&gt;%  \n    `colnames&lt;-`(stringr::str_to_lower(names(.)))%&gt;% \n    `colnames&lt;-`(gsub(\"kernal\",\"kernel\",names(.))) %&gt;% \n    `colnames&lt;-`(gsub(\"spikes\",\"spike\",names(.)))%&gt;%\n    `colnames&lt;-`(gsub(\"plot.id\",\"plot_id\",names(.))) %&gt;% \n    mutate(student=student_name)\n}) \ndf %&lt;&gt;% mutate(var=\"Capone\",plot_id=159) %&gt;% \n  .[!grepl(\"na.\",names(.))]\ndf %&gt;% glimpse()\n\nRows: 57\nColumns: 8\n$ var          &lt;chr&gt; \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone~\n$ plot_id      &lt;dbl&gt; 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 15~\n$ spike        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\n$ flower       &lt;dbl&gt; 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, ~\n$ kernel.full  &lt;dbl&gt; 0, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, ~\n$ kernel.half  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ student      &lt;chr&gt; \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"c~\n\n\n\n2.1 How to make it a bit more beautiful?\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(flower,spike,color=student))+\n  geom_point()+\n  geom_path(alpha=.5)+\n  facet_grid(~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n2.2 How to place kernel-related traits in subplots?\n\n\n\n\n\n\npivot_longer()to collect kernel-related traits\nfacet_grid()\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  pivot_longer(starts_with(\"kernel\"),\n               values_to = \"kernel\",\n               names_to=\"kerneltype\") %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(kernel,spike,color=student))+\n  geom_point()+\n  geom_path()+\n  facet_grid(kerneltype~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n2.3 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\n\n\n\n\n\n\nbasal 1/3 spikelet from the bottom)\ncentral (middle 1/3 of spikelets)\napical (1/3 spikelets from the top)\n\nreference\n\n\n\ntry to clssify each spike into three classes based on their position.\n\n\n\n\n\n\nchallenge\n\n\n\n\nadd new column called type using mutate()\ncut() could be useful, which column you should apply to?\nwhat will you get when you pass the result of cut() to as.numeric()?\nuse case_when() to re-calssify the result of step 3.\nbased on which columns should you classify? what are your group columns for group_by?\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&lt;&gt;% \n  group_by(student,plot_id,var) %&gt;% \n  mutate(type=cut(spike,3) %&gt;% as.numeric(),\n         type=case_when(type==1~\"basal\",\n                        type==2~\"central\",\n                        T~\"apical\"))\n\n\n\n\ngo to ?@sec-realclass for more practices.\n\n\n\n\n\nHow to plot this half-box plot?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nlibrary(ggpol)\np &lt;- df%&gt;% \n  ggplot(aes(type,flower,fill=student))+\n  geom_boxjitter(aes(color=student),alpha=.4,\n                 jitter.shape = 21, jitter.color = NA, \n                 jitter.params = list(height = 0, width = 0.04),\n                 outlier.color = NA, errorbar.draw = TRUE)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"bottom\") \n\nprint(p)\n\n\n\n\n\n\n2.4 how to change the order of the box plot?\nset the type as factor and arrange the levels from basal to apical."
  },
  {
    "objectID": "posts/Week10/index.html",
    "href": "posts/Week10/index.html",
    "title": "Week11: Grain development vI",
    "section": "",
    "text": "Welcome to the eleventh course! You will learn more aboutdata visualization:"
  },
  {
    "objectID": "posts/Week10/index.html#story-telling-warm-up-for-final-presentation",
    "href": "posts/Week10/index.html#story-telling-warm-up-for-final-presentation",
    "title": "Week11: Grain development vI",
    "section": "1 Story telling: Warm up for final Presentation",
    "text": "1 Story telling: Warm up for final Presentation\n\n\n\nFigure1: Project Plan\n\n\n\n\n\nFigure2: Story type\n\n\n\n\n\nFigure3: Cycle of visualization\n\n\n\n\n\nVisualization based on data type: click picture for source\n\n\n1 21 Ten simple rules for better figures2 How to Make Good Graphs and Figures for Scientific Papers"
  },
  {
    "objectID": "posts/Week10/index.html#exercise-with-students-data",
    "href": "posts/Week10/index.html#exercise-with-students-data",
    "title": "Week11: Grain development vI",
    "section": "2 Exercise with student’s data",
    "text": "2 Exercise with student’s data\npractice with files from data/student.\n\nlibrary(magrittr)\ndf&lt;- map_dfr(list.files(\"../data/student\"),~{\n  \n  student_name &lt;-  .x %&gt;% strsplit(\"_\") %&gt;% unlist() %&gt;% \n    .[4] %&gt;% sub(\".xlsx\",\"\",.)\n  \n  file&lt;- xlsx::read.xlsx(paste0(\"../data/student/\",.x),sheetIndex = 1) %&gt;%  \n    `colnames&lt;-`(stringr::str_to_lower(names(.)))%&gt;% \n    `colnames&lt;-`(gsub(\"kernal\",\"kernel\",names(.))) %&gt;% \n    `colnames&lt;-`(gsub(\"spikes\",\"spike\",names(.)))%&gt;%\n    `colnames&lt;-`(gsub(\"plot.id\",\"plot_id\",names(.))) %&gt;% \n    mutate(student=student_name)\n}) \ndf %&lt;&gt;% mutate(var=\"Capone\",plot_id=159) %&gt;% \n  .[!grepl(\"na.\",names(.))]\ndf %&gt;% glimpse()\n\nRows: 57\nColumns: 8\n$ var          &lt;chr&gt; \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone\", \"Capone~\n$ plot_id      &lt;dbl&gt; 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 15~\n$ spike        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\n$ flower       &lt;dbl&gt; 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, ~\n$ kernel.full  &lt;dbl&gt; 0, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, ~\n$ kernel.half  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ student      &lt;chr&gt; \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"c~\n\n\n\n2.1 How to make it a bit more beautiful?\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(flower,spike,color=student))+\n  geom_point()+\n  geom_path(alpha=.5)+\n  facet_grid(~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n2.2 How to place kernel-related traits in subplots?\n\n\n\n\n\n\npivot_longer()to collect kernel-related traits\nfacet_grid()\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&gt;% \n  pivot_longer(starts_with(\"kernel\"),\n               values_to = \"kernel\",\n               names_to=\"kerneltype\") %&gt;% \n  group_by(student,spike) %&gt;% \n  ggplot(aes(kernel,spike,color=student))+\n  geom_point()+\n  geom_path()+\n  facet_grid(kerneltype~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"none\")\n\n\n\n\n\n\n2.3 classify spikelet based on position\nthe spike of the main shoot was dissected to count the total number of floret in\n\n\n\n\n\n\n\nbasal 1/3 spikelet from the bottom)\ncentral (middle 1/3 of spikelets)\napical (1/3 spikelets from the top)\n\nreference\n\n\n\ntry to clssify each spike into three classes based on their position.\n\n\n\n\n\n\nchallenge\n\n\n\n\nadd new column called type using mutate()\ncut() could be useful, which column you should apply to?\nwhat will you get when you pass the result of cut() to as.numeric()?\nuse case_when() to re-calssify the result of step 3.\nbased on which columns should you classify? what are your group columns for group_by?\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf %&lt;&gt;% \n  group_by(student,plot_id,var) %&gt;% \n  mutate(type=cut(spike,3) %&gt;% as.numeric(),\n         type=case_when(type==1~\"basal\",\n                        type==2~\"central\",\n                        T~\"apical\"))\n\n\n\n\ngo to Section 3.2 for more practices.\n\n\n\n\n\nHow to plot this half-box plot?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nlibrary(ggpol)\np &lt;- df%&gt;% \n  ggplot(aes(type,flower,fill=student))+\n  geom_boxjitter(aes(color=student),alpha=.4,\n                 jitter.shape = 21, jitter.color = NA, \n                 jitter.params = list(height = 0, width = 0.04),\n                 outlier.color = NA, errorbar.draw = TRUE)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"bottom\") \n\nprint(p)\n\n\n\n\n\n\n2.4 how to change the order of the box plot?\nset the type as factor and arrange the levels from basal to apical.\n\n\n\n\n\n\n\n2.5 summarize\n\n\n\n\n\n\nbasic summary of kernel development summ for single spike\n\nSp: total spikelet\nFl: maximum floret\nsfl: total floret\nkf: total full kernel\nkh: total half kernel\nks: total small kernel\nkp: potential kernel number (half+pull)\nfr: filling rate (full kernel/ floret number)\nfc: potential filling rate (potential kernel number/ floret number)\n\n\n\n\nsee also Section 3.3 for another example.\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\nsum.df &lt;- df %&gt;% \n  dplyr::group_by(student,var,plot_id,type) %&gt;% \n  dplyr::summarise(\n    Sp=max(spike),#total spikelet\n    Fl=max(flower),# maximum floret \n    sfl=sum(flower),# total floret\n    kf=sum(kernel.full,na.rm = T),# total full kernel\n    kh=sum(kernel.half,na.rm = T),# total half kernel\n    ks=sum(kernel.small,na.rm = T),# total small kernel\n    kp=kf+kh,# potential kernel number \n    fr=kf/sfl,# filling rate \n    fc=kf/kp)#potential filling rate\n\n\n\n\n\n\n2.6 how to visualize the maximum full kernels per spikelet?\nFor each spike position, how many maximum full kernels can you have?\n\n\n\n\n\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndf%&gt;% \n  group_by(student,var,plot_id,type,spike) %&gt;% \n  summarise(fertile_flower=max(kernel.full)) %&gt;% \n  ggplot(aes(fertile_flower,spike,color=type))+\n  geom_point()+\n  facet_grid(~student)+\n  theme_classic()+\n  theme(strip.background = element_blank(),\n        panel.grid.major.x = element_line(),\n        legend.position = \"bottom\")+\n  geom_path()"
  },
  {
    "objectID": "posts/Week10/index.html#practice-on-a-larger-dataset",
    "href": "posts/Week10/index.html#practice-on-a-larger-dataset",
    "title": "Week11: Grain development vI",
    "section": "3 Practice on a larger dataset",
    "text": "3 Practice on a larger dataset\n\nread kernel_combine.csv in folder data using relative path.\nsubset column tiller which match the pattern M.\n\n\n3.1 how to get overview of unique combinations?\nHow can you get the unique combination of car,var,nitrogen and time? Which combinations of functions can you use?\n\n\n\n\n\n\nclick for answer\n\n\n\n\n\n\ndat %&gt;% \n  group_by(car,var,nitrogen,time) %&gt;% \n  summarise()\n\n\n\n\n\n\n3.2 classify spikelet based on position\nsee Section 2.3 for definition.\n\n\nRows: 4,749\nColumns: 12\nGroups: car, var, nitrogen, time, rep, type [681]\n$ car          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ nitrogen     &lt;chr&gt; \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3\", \"n3~\n$ time         &lt;chr&gt; \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1~\n$ var          &lt;chr&gt; \"Pioneer\", \"Alves\", \"Potential\", \"Torrid\", \"Torrid\", \"Alv~\n$ rep          &lt;int&gt; 1, 1, 1, 1, 2, 3, 1, 2, 3, 2, 5, 4, 4, 4, 5, 5, 5, 5, 5, ~\n$ tiller       &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M~\n$ spike        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ flower       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ~\n$ kernel.full  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.half  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ kernel.small &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ type         &lt;chr&gt; \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"basal\", \"ba~\n\n\n\n\n3.3 basic summary of kernel development summ for single spike\nsee Section 2.5 for definition.\n\n\nRows: 681\nColumns: 15\nGroups: nitrogen, time, var, rep, tiller [227]\n$ nitrogen &lt;chr&gt; \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"n1\", \"~\n$ time     &lt;chr&gt; \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"t1\", \"~\n$ var      &lt;chr&gt; \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\", \"Alves\"~\n$ rep      &lt;int&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2~\n$ tiller   &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"~\n$ type     &lt;chr&gt; \"apical\", \"basal\", \"central\", \"apical\", \"basal\", \"central\", \"~\n$ Sp       &lt;int&gt; 16, 6, 11, 19, 7, 13, 17, 6, 11, 19, 7, 13, 19, 7, 13, 16, 6,~\n$ Fl       &lt;int&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4~\n$ sfl      &lt;int&gt; 19, 18, 20, 21, 21, 24, 22, 20, 20, 21, 22, 24, 18, 21, 24, 1~\n$ kf       &lt;int&gt; 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ kh       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ ks       &lt;int&gt; 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0~\n$ kp       &lt;int&gt; 10, 8, 13, 14, 11, 18, 13, 11, 15, 12, 12, 17, 9, 12, 17, 2, ~\n$ fr       &lt;dbl&gt; 0.5263158, 0.4444444, 0.6500000, 0.6666667, 0.5238095, 0.7500~\n$ fc       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n\n\n\n\n3.4 Data wrangling and plot with facet\n\n\n\n\n\n\n\nstep1 create long format\n\n\ncreate long format long_format, combine nitrogen and time, names to “treatment” values to “levels”\nfor each rep,levels,type,var,spike,treatment calculate the maximum full kernel and name it fertile_flower.\nfor each levels,type,var,spike,treatment calculate the mean fertile_flower.\n\n\n\n\n\n\n\n\n\n\n\nstep2 visualize\n\n\nsubset the value of fertile_flowerless than 10\nbased on this graph, what is x, y, color and shape?\nwhat re the facet?"
  },
  {
    "objectID": "posts/Week10/index.html#recommendation",
    "href": "posts/Week10/index.html#recommendation",
    "title": "Week11: Grain development vI",
    "section": "4 recommendation",
    "text": "4 recommendation\nDatavisualization Scientific story telling"
  },
  {
    "objectID": "phenotyping_rule.html",
    "href": "phenotyping_rule.html",
    "title": "Protocol",
    "section": "",
    "text": "Treatment to compare: early and late\n\nOther info (total nitrogen 176 kg/ha, split application of heading fertilizer, replicate 1).\nCultivar: Student A(Capone) Student B (Patras, Pionier) Student C (Potenzial)\n\nDate: 5 batches from 11.\n\n\n\n\n\n\n\nFigure 1: Selected treatment and var"
  },
  {
    "objectID": "phenotyping_rule.html#protocol",
    "href": "phenotyping_rule.html#protocol",
    "title": "Protocol",
    "section": "Protocol",
    "text": "Protocol\n\nClean up the table. Place one A4 paper on the table.\nTake out one ear at a time from a bag containing 10 ears.\ndownload grain_counting_example.xlsx from HuBox\nCopy to your repository under relative path ./data/Grain_Counting/ save it as gc_plotid_batch.xlsx (Figure 2)\nEnter information of var, plot_id and ear number (from 1 to 10)\nCount total spikelet number (Nsp), record the sequence 1: Nsp in column spike.\nCount the floret number (Nf) based on Nsp with ascending order (start from spikelet 1).\nClassify the shape of fully developed kernel into three classes (L,M,S), record the position of each class, separate them with comma (,). For example: 1,2,3 for class kernel.L (Figure 2)\nAborted kernel will not be recorded in column F:H. However, if special condition observed, you can record it in column I (with column name note) and take a picture of it.\nRoll your ear with another half-A4 paper like a candy. Make sure you have the ear number and plotid on the outer side of the paper. And put it back to the bag.\nCheck the correctness and completeness of the data in current sheet. Save the data, start another ear in a new sheet.\nGet up and take a small break!\n\n\n\n\nFigure 2: Figure 2\n\n\n\n\n\n\n\n\nChallenge: automatize process of reading files\n\n\n\nUse the code below to reach the following goals.\n\nWrite a for loop to read all the files and sheets in the folder\nadd batch information to column\n\n\nlibrary(dplyr)\np &lt;- \".data/Grain_Counting/gc_57_11.xlsx\"\ndf &lt;- readxl::read_xlsx(p) %&gt;% \n  mutate(across(starts_with(\"kernel\"),function(x)as.character(x))) %&gt;% \n  tidyr::pivot_longer(starts_with(\"kernel\"),names_to = \"kernel.type\",values_to = \"floret.pos\") %&gt;% \n  mutate(floret.pos=strsplit(floret.pos,\",\")) %&gt;% \n  tidyr::unnest(floret.pos) %&gt;% \n  mutate(floret.pos=as.numeric(floret.pos) %&gt;%replace(., is.na(.), 0))"
  },
  {
    "objectID": "phenotyping_rule.html#goal",
    "href": "phenotyping_rule.html#goal",
    "title": "Protocol",
    "section": "",
    "text": "Treatment to compare: early and late\n\nOther info (total nitrogen 176 kg/ha, split application of heading fertilizer, replicate 1).\nCultivar: Student A(Capone) Student B (Patras, Pionier) Student C (Potenzial)\n\nDate: 5 batches from 11.\n\n\n\n\n\n\n\nFigure 1: Selected treatment and var"
  },
  {
    "objectID": "posts/Week1/index.html#r-basic",
    "href": "posts/Week1/index.html#r-basic",
    "title": "Week1: Phenology and the growth of spike",
    "section": "",
    "text": "Press Ctrl+ Shift +Nto open new script.Save it as Week1_practice.R Copy code from this website to your script and press run.\nSave ### Concept of datatype & case sensitive Rules:\n\nDon’t compete your variable names with system. (eg., var,mean,aov)\n\nsomething that will show in the drop down menu of auto-completion.\n\nDon’t start with number.\nSeparate long name with _.\n\n\nvariable\n# assignment str\"v\" to name \"variable\"\n## \"\" and unquote str and variable \n\nvariable &lt;- \"v\"\nVariable &lt;- 1\nvariable +1\nVariable +1 \n\n\n\n\n# str??\nstr\n?str\nstr(variable)\nstr(Variable)\n# data type coersion\nstr(NA)\nstr(c(NA,1))\nstr(c(NA,\"a\"))\nstr(c(NA,TRUE))\nstr(c(1,\"a\"))\n\n\n\n\nCheck this great package tidyverse!\n\nNote that windows user may need to first download the Rtools that match your R version.\n\nYou can check your R version by typing version() in your R console.\n\ninstall.packages(tidyrverse)\ninstall.packages(\"tidyrverse\")\nlibrary(dplyr)\n\n\n\n\nPipe (%&gt;%) is available in r-package either dplyr or magrittr.\nPlease use %&gt;% to avoid embedded functions.\n.stands for the result from the left side of the pipe.\nFor long line code, press enter after each %&gt;%.\nSelect all the codes by ctrl A.\nIndent the selected codes by ctrl I.\n\n# syntax of using pipe\n\nfun1(object)\n\nobject %&gt;% fun1(.)\nobject %&gt;% fun1()\nobject %&gt;% fun1() %&gt;% .\nobject %&gt;% fun1(.) %&gt;% .\n\n#embedded functions\nfun2(fun1(object))\n# pipe\nobject %&gt;% \n  fun1() %&gt;% \n  fun2()\n\n\n# how many ways of creating a sequence?\nc(1,2,3)\nseq(1,3,1)\n\n# embedded function : fun2(fun1())\nlength(c(1,2,3))\n# use pipe, \".\" is the result of previous step\nc(1,2,3) %&gt;% length(.)\n\n# replicate element as vector\nrep(1,3)\n# remove duplicates\nrep(1,3) %&gt;% unique()\n# cumulative sum \nrep(1,3) %&gt;% cumsum()\n\n# is there any difference?\npaste(c(\"a\",\"1\"),collapse = \"\")\npaste0(c(\"a\",\"1\"))\npaste0(\"a\",\"1\")\n\n\nUse str() to check the data type of above line.\nYou have two vectors, c(\"a\",\"b\") and c(\"1\",\"2\")\nHow to use paste and repto create sequence of char vector shown below?\nCheck the arguments of rep to get more hints. e.g.,\nrep(c(\"a\",\"b\"),each=2)\nrep(c(\"a\",\"b\"),times=2)\n\n\n\n[1] \"a1\" \"a2\" \"b1\" \"b2\"\n\n\n[1] \"a1\" \"b1\" \"a2\" \"b2\"\n\n\n\n\n\nformat: function_name(argument1, argument2) {code} example:\n\nplusone &lt;- function(x){\n  x+1\n}\n# is function data type sensitive?\nplusone(variable)\nplusone(Variable) \n\nfunction with good documentation example:\n\nfunction_name  &lt;-function(input){\n  # input: datatype, length, meaning.\n  # output: datatype, length, meaning.\n  # action1: intermediate_variable &lt;- input %&gt;% fun1()\n  # action2: output &lt;-intermediate_variable%&gt;% fun2()\n  ...\n  return(output)\n}\n\n\nwrite a function with documentation: input vec is a numeric vector with length 3, return str of average value of vec ± standard deviation of vec.\nVisualize the step in your function by first writing your the possible steps in text!\n\n\n\n\n\nas.Date(\"2023-04-17\")\nas.Date(\"2023-04-17\",format=\"%Y-%m-%d\")\n# is ther any error?\nas.Date(\"20230417\")\nas.Date(\"17042023\")\n# additive properties of Date \nas.Date(\"2023-04-17\")-7\nas.Date(\"2023-04-17\")+2\n\n\nSince type Date is additive, how to create successive date vector of length 5? Vector date start with “2023-04-17”\nCould you do the average of this vector?\n\n\n\n[1] \"2023-04-17\" \"2023-04-18\" \"2023-04-19\" \"2023-04-20\" \"2023-04-21\"\n\n\n\n\n\n\n# check if pattern exist in vector\n3%in%c(1,3) \n2%in%c(1,3) \n\n1==2 \n!1==2 \n1!=2 \nc(1,3)==2\n\nwhich(c(1,3)==3) \n\n# what will be the difference?\norder(c(3,1,2)) \nc(3,1,2) %&gt;% .[order(.)]\n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "project_description.html",
    "href": "project_description.html",
    "title": "Project description",
    "section": "",
    "text": "Project draft due Tue, 12 Dec, week8\nSlides presentation and final GitHub repo due Tue, Feb 13\n\n\n\n\n\n\n\nExpectted results\n\n\n\nThe three primary deliverables for the final project are\n\nA GitHub repository\nA Slides presentation\nA ReadMe\nA written, reproducible report in Markdown"
  },
  {
    "objectID": "project_description.html#timeline",
    "href": "project_description.html#timeline",
    "title": "Project description",
    "section": "",
    "text": "Project draft due Tue, 12 Dec, week8\nSlides presentation and final GitHub repo due Tue, Feb 13\n\n\n\n\n\n\n\nExpectted results\n\n\n\nThe three primary deliverables for the final project are\n\nA GitHub repository\nA Slides presentation\nA ReadMe\nA written, reproducible report in Markdown"
  },
  {
    "objectID": "project_description.html#introduction",
    "href": "project_description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nThe goal of the final project is for you to use scientific analysis to analyze a data set of your own. Be aware the phenotyping takes time, plan your schedule in advance.!\nThe goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nExpectted results\nThe three primary deliverables for the final project are\n\nA ReadMe about the project\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides presentation"
  },
  {
    "objectID": "project_description.html#topic-ideas",
    "href": "project_description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 research questions you’re interested in potentially using for the final project. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you’re interested in investigating and find other scientific publication on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\n\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project_description.html#project-proposal",
    "href": "project_description.html#project-proposal",
    "title": "Project description",
    "section": "2 Project draft",
    "text": "2 Project draft\nThe purpose of writing the draft at the early stage is to help you think about your analysis strategy. Your presentation could also be prepared based on this structure.\nIn your draft, you should have:\n\n2.1 Section 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\n2.2 Section 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\n2.3 Section 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\n\n\n\n2.4 Data dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal.\n\n\n2.5 Submission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Moodle."
  },
  {
    "objectID": "project_description.html#draft-report",
    "href": "project_description.html#draft-report",
    "title": "Project description",
    "section": "5 Project report",
    "text": "5 Project report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft\nBelow is a brief description of the sections to focus on in the draft:\n\n5.1 Introduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n5.2 Methodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\n5.3 Results\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project_description.html#peer-review",
    "href": "project_description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nProcess and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project_description.html#written-report",
    "href": "project_description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question.\n\n\n\nResults\nDescribe the key results from the graph. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe visualization is clearly assessed, and interesting findings are clearly described. Interpretations of statistical test are used to support the key findings and conclusions, rather than merely visual comparison.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the statistical results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe presentation neatly prepared and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. All code, warnings, and messages are suppressed. Presentation is in time.\n\n\n\nSlides\nYou need to create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Previous research that relevant to your hypothess\nSlide 3: Hypotheses Research questions\nSlide 4: Introduce the data\nSlide 5: Calculation\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project_description.html#video-presentation-slides",
    "href": "project_description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nYou need to create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Previous research that relevant to your hypothess\nSlide 3: Hypotheses Research questions\nSlide 4: Introduce the data\nSlide 5: Calculation\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick “Start a new conversation”.\nMake the title “Your Team Name: Project Title”. For example, “Teaching Team: Our Awesome Presentation”.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click “Insert 1 item.” This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou’re done!"
  },
  {
    "objectID": "project_description.html#presentation-comments",
    "href": "project_description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group’s video, then click “Reply” to post a question for the group. You may not post a question that’s already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn’t be “Why did you use a bar plot instead of a pie chart”?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group’s specific presentation, i.e demonstrating that you’ve watched the presentation."
  },
  {
    "objectID": "project_description.html#reproducibility-organization",
    "href": "project_description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project_description.html#peer-teamwork-evaluation",
    "href": "project_description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project_description.html#overall-grading",
    "href": "project_description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "course_description.html",
    "href": "course_description.html",
    "title": "Course description",
    "section": "",
    "text": "The goal of the final project is for you to use scientific analysis to analyze a data set of your own. Be aware the phenotyping takes time, plan your schedule in advance!\nThe goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (share it on Github).\n\n\n\nCourse design"
  },
  {
    "objectID": "course_description.html#presentation-100",
    "href": "course_description.html#presentation-100",
    "title": "Course description",
    "section": "Presentation (100%)",
    "text": "Presentation (100%)\n\nR code reproducibility & documentation on Github repository (50%)\nOral presentation in 15 mins (50%)\n\n\nRequirements for oral presentation:\n\nResearch question, hypothesis\nMethod\nResults\nDiscussion\nfollowing scientific presentation standard."
  },
  {
    "objectID": "course_description.html#requirements-for-oral-presentation",
    "href": "course_description.html#requirements-for-oral-presentation",
    "title": "Grading",
    "section": "Requirements for oral presentation:",
    "text": "Requirements for oral presentation:\n\nResearch question, hypothesis\nMethod\nResults\nDiscussion"
  },
  {
    "objectID": "notuse/about.html",
    "href": "notuse/about.html",
    "title": "About",
    "section": "",
    "text": "This blog was build for the IPFS BSC project course 2023 summer semester."
  },
  {
    "objectID": "notuse/sylabus.html",
    "href": "notuse/sylabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "penguin_table %&gt;% as_raw_html()\n\n\n\n  \n  \n  \n    \n      Penguins in the Palmer Archipelago\n    \n    \n      Data is courtesy of the {palmerpenguins} R package\n    \n    \n      \n      \n        Adelie\n      \n      \n        Chinstrap\n      \n      \n        Gentoo\n      \n    \n    \n      Female\n      Male\n      Female\n      Male\n      Female\n      Male\n    \n  \n  \n    \n      Island: Biscoe\n    \n    2007\n5\n5\n-\n-\n16\n17\n    2008\n9\n9\n-\n-\n22\n23\n    2009\n8\n8\n-\n-\n20\n21\n    \n      Island: Dream\n    \n    2007\n9\n10\n13\n13\n-\n-\n    2008\n8\n8\n9\n9\n-\n-\n    2009\n10\n10\n12\n12\n-\n-\n    \n      Island: Torgersen\n    \n    2007\n8\n7\n-\n-\n-\n-\n    2008\n8\n8\n-\n-\n-\n-\n    2009\n8\n8\n-\n-\n-\n-"
  },
  {
    "objectID": "project_description.html#readme",
    "href": "project_description.html#readme",
    "title": "Project description",
    "section": "ReadMe",
    "text": "ReadMe\nFor each repo, include the following:\n\nIntroduction and data\n\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set Example dataset code repo"
  },
  {
    "objectID": "course_description.html#introduction",
    "href": "course_description.html#introduction",
    "title": "Course description",
    "section": "",
    "text": "The goal of the final project is for you to use scientific analysis to analyze a data set of your own. Be aware the phenotyping takes time, plan your schedule in advance!\nThe goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (share it on Github).\n\n\n\nCourse design"
  },
  {
    "objectID": "posts/Week2/index.html#what-is-working-directory-wd",
    "href": "posts/Week2/index.html#what-is-working-directory-wd",
    "title": "Week2: The growth of spike in winter wheat",
    "section": "",
    "text": "\".\" means the working directory (wd) where this R script exists.\n\"..\" means the parent (one level higher) directory of \".\".\n\nlibrary(dplyr)\n\n# working directory, abbreviated as \".\"\ngetwd()\n# parent directory, abbreviated as \"..\"\ndirname(getwd())\n# assign current path to variable\ncurrent_path &lt;- getwd()\n# check the type \ncurrent_path %&gt;% str()\n\n\n# check files in the directory\n\n# are they different?\n\".\" %&gt;% list.files(path=.)\ngetwd() %&gt;% list.files(path=.)\n\n# are they different?\n\"..\" %&gt;% list.files(path=.)\ngetwd() %&gt;% dirname() %&gt;% list.files(path=.)\n\n\nAlthough the meaning of . is the same as getwd(), the content is depending on the environment you are working with.\nRight click R studio logo, open a new R studio window, compare the result of getwd() in R project and R\n\n\n\n\nWhich one do you prefer? Why do we prefer relative path?\n\n# absolute path, did you get error?\n\"C:/Users/marse/seadrive_root/Tien-Che/My Libraries/PhD_Tien/Project/Postdoc_teaching/BSC_project_IPFS2023/data\" %&gt;% list.files(path=.)\n# relative path in R base\nparent_path &lt;- getwd() \npaste0(parent_path,\"/data\") %&gt;% list.files(path=.)\n\n# Does this works? \n\".\\data\" %&gt;% list.files(path=.)\n\"data\" %&gt;% list.files(path=.)\n\n\nread from relative path, which one is correct? Assume working directory current_path is \"C/users/BSC_project/src\"\nAbsolute_path = current_path +\"/\"+relative_path Below are four relative paths. Please rewrite them in absolute (full) path form. What should . be replace? Which two are the same? Based on the figure illustated below, path 1-4 should be A,B,C or D?\n\n\"ear_summarized.csv\"\n\"data/ear_summarized.csv\"\n\"./data/ear_summarized.csv\"\n\"../data/ear_summarized.csv\""
  },
  {
    "objectID": "posts/Week2/index.html#subsetting-element-from-vetor-with-accessors",
    "href": "posts/Week2/index.html#subsetting-element-from-vetor-with-accessors",
    "title": "Week2: The growth of spike in winter wheat",
    "section": "",
    "text": "vector indexing start from 1 to the length of the vector.\n\nempty_vec &lt;- c()\nlength(empty_vec)\n# what is the type of the empty vec?\nempty_vec %&gt;% str()\n\n# NULL: empty \nempty_vec[1]\nempty_vec[0]\n\n\nvec &lt;- c(1,3,5)\nvec[1]\n#reorder the vector \nvec[c(2,1,3)]\n# removing the indexed elements\nvec[-1]\nvec[-2]\n\n# indexing start from 1, not 0\n# therefore you get, numeric(0)\nvec[0]\n# when access exceeding the range of a vector, what datatype do you get? \nvec[4]\nvec %&gt;% .[length(.)+1]\nvec[1:4]\nvec[4:1]\n\n# find specific element or position\nvec[c(F,T,F)]\nvec[vec==5]\n# when codition not match at all, it will return? \nvec[vec==2]\nvec[c(F,F,F)]\nvec %&gt;% .[c(F)]\nvec[vec==\"a\"]\n\n# default str vector\nletters\nLETTERS\n# when the query does not match, guess what will be the datatype? \nletters %&gt;% .[.==2]\nletters %&gt;% .[c(F)]\n# vector over write\nvec\nvec &lt;- c(2,1,3)\nvec\n\n\n\nvec &lt;- c(1, 2, 3, 4, 5)\nlogical_vec &lt;- c(TRUE, FALSE)\nsubset_vec &lt;- vec[logical_vec]\nsubset_vec\n\n[1] 1 3 5\n\n\nwhat did you observe? Is there any vector recycling?\nWhat happen when you enter vec[TRUE]?\n\nSupplementary information of special datatypes:\nEmpty : NULL\nIndexing at zero position:numeric(0)\n\n\nlist_object&lt;- list(element_name=value) Make a list is like put a cookie(content of list element) in the cookie jar(list element).\nThere are 3 common accessors for list: 1. access the list element (cookie jar)\n[] access the list position\n\nacess the content of list element (cookie)\n\n[[]] access the content of a list element by position or name\n$ access the content of a list element by name\nlist_object$element_name or list_object[[element_name]]\n\n\n\nlist without name\n\n\n\n\n\nlist with name\n\n\nMore about the accessors\n\n# create a simple list\nlist(1)\n# create a simple list with name \"x\" for first element\nlist(x=1)\nlist(x=1)[\"x\"]\n# extract content\nlist(x=1)$\"x\"\nlist(x=1)[[1]]\nlist(x=1)[[\"x\"]]\n\n# extract with pipe\nlist(x=1) %&gt;% .[[1]]\nlist(x=1) %&gt;% .$\"x\"\n\n# long list\nlong_list_example &lt;- list(1,c(1,2),\n                          T,c(T,T),\n                          \"str\",c(\"a\",\"b\"),\n                          list(1),\n                          mean,data.frame())\n# check structure of this list \n# list_complex_example %&gt;% str()\n# list_complex_example %&gt;% glimpse()\n# list_complex_example\n# first list \nlong_list_example[1]\n# content of first list\nlong_list_example[[1]]\n# first element of content of first list\nlong_list_example[[1]][1]\n\n\ncan you guess what data type are these?\n\n# non-sense\nlong_list_example[[1]][2]\nlong_list_example[1][1]\nlong_list_example[1][2]\nlong_list_example[2][2]\n# meaningful\nlong_list_example[[2]][2]\n\n\n\n\n\nlapply(vector, function) ?lapply\n\n# input is vector\nc(1,4) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input is list\nlist(2,4,c(1,4)) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input has differnt type\nlist(2,4,c(1,4),\"8\") %&gt;% \n  lapply(.,FUN=function(x){x+3})\n\n\nWhy you get error in the last line?\n\n\n\n\neach column has one data type\n\n# create a dataframe \ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\\temp=c(20,15,13),\\thermal_time=cumsum(c(20,15,13)))\n# another way\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) \ndf$temp=c(20,15,13)\ndf$thermal_time=cumsum(df$temp)\n\n# third method\nlibrary(dplyr)\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) %&gt;% \n  mutate(temp=c(20,15,13), \n         thermal_time=cumsum(temp))\ndf\n\n\nIs it possible to create data frame with vectors of different length?\n\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1), \n           temp=c(20,13))\n\n\n\n\n\nYou can subset dataframe by indexing [row,column]\ndataframe[,column] select the whole role for selected columnn\ndataframe[row,] select the whole column of selected rows\nSelect multiple row or column by puting logical or numeric vector in the square bracket.\n\nuse df,\n\nAccess column thermal_time as vector\nExtract temp when time is 2023-04-17\nExtract first row and first column with [1,]and [,1]\n\n\n\nif you want to turn a data frame (df) by 90 degree (“transpose”), which function can you use? Could you find the answer on google or chatGPT?"
  },
  {
    "objectID": "posts/Week1/index.html#set-up-your-working-directory",
    "href": "posts/Week1/index.html#set-up-your-working-directory",
    "title": "Week1: R studio, vector and function",
    "section": "1 Set up your working directory",
    "text": "1 Set up your working directory\n\n1.1 preparation\n\nPlease make sure you have installed R & Rstudio.\n\n\n\nOpen Rstudio, File -&gt; New Project -&gt; Wheat_BSC_project, click create a git repository\ndownload the data from HU-box, save it in data.\ncreate Week1.R and save it in folder src.\nOpen github desktop\n\n\n \n\n\ncomment&commit & push\n\n\n\nPress Ctrl+ Shift +Nto open new script.\nSave it as Week1.R Copy code from this website to your script and press run.\n\n\n\n\n‘folder structure’\n\n\n\n\n1.2 Concept of datatype & name space:\n\nDon’t overwrite variable names in name space (what already exists in system).\n\neg., var,mean,aov, etc.\n\n\n\n\n\n\n\n\nWarning\n\n\n\navoid something that will show in the drop down menu of auto-completion.\n\n\n\n\n\nSeparate long variable names with _.\n\neg., thermal_time,mean_yield, etc.\n\nDon’t start variable names with number.\n\n\n\n\n\nBad\nBetter\n\n\n\n\n\n3years\nthree_years\n\n\n\n1225measurement\nmeasurement_1225\n\n\n\n13genotypes\ngenotypes_13\n\n\n\n\n\n\nStructure of a vector\n\n\nVariable = variable names + object"
  },
  {
    "objectID": "posts/Week1/index.html#data-type-is-everything",
    "href": "posts/Week1/index.html#data-type-is-everything",
    "title": "Week1: R studio, vector and function",
    "section": "2 Data type is everything",
    "text": "2 Data type is everything\n\nvariable\n# assignment str\"v\" to name \"variable\"\n## \"\" and unquote str and variable \nvariable &lt;- \"v\"\nVariable &lt;- 1\n\nvariable +1\nVariable +1 \n\n\n2.1 Always check your data type first!\n\n# str??\nstr\n?str\nstr(variable)\nstr(Variable)\n# data type coersion\nstr(NA)\nstr(c(NA,1))\nstr(c(NA,\"a\"))\nstr(c(NA,TRUE))\nstr(c(1,\"a\"))\n\n\n\n2.2 Date\n\nas.Date(\"2023-04-17\")\nas.Date(\"2023-04-17\",format=\"%Y-%m-%d\")\n# is ther any error?\nas.Date(\"20230417\")\nas.Date(\"17042023\")\n# additive properties of Date \nas.Date(\"2023-04-17\")-7\nas.Date(\"2023-04-17\")+2"
  },
  {
    "objectID": "posts/Week1/index.html#function-something-ends-with",
    "href": "posts/Week1/index.html#function-something-ends-with",
    "title": "Week1: R studio, vector and function",
    "section": "3 Function: something ends with ()",
    "text": "3 Function: something ends with ()\n\n\n\nHow function works?\n\n\n\n# example: fun(object)\nc(1,2,3)\nseq(1,3,1)\n\nmean(c(1,2,3))\nstr(TRUE)\n\n\n3.1 r packages : collection of functions\nCheck this great package tidyverse!\n\nNote that windows user may need to first download the Rtools that match your R version.\n\nYou can check your R version by typing version() in your R console.\n\ninstall.packages(dplyr)\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\n\n\n3.2 separate individual function from nested functions with %&gt;%\nPipe (%&gt;%) is available in r-package either dplyr or magrittr.\nPlease use %&gt;% to avoid embedded functions.\n.stands for the result from the left side of the pipe.\nFor long line code, press enter after each %&gt;%.\nSelect all the codes by ctrl A.\nIndent the selected codes by ctrl I.\nConcepts of using pipe\n\n# syntax of using pipe\nlibrary(dplyr)\n\nfun1(object)\n# .= object\nobject %&gt;% fun1(.)\n# . could be also skipped\nobject %&gt;% fun1()\n\n# . = fun1(object)\nobject %&gt;% fun1() %&gt;% .\nobject %&gt;% fun1(.) %&gt;% .\n\n#embedded functions\nfun2(fun1(object))\n# .=fun2(fun1(object))\nobject %&gt;% \n  fun1() %&gt;% \n  fun2() %&gt;% .\n\nExamples of using pipe\n\n# how many ways of creating a sequence?\nc(1,2,3)\nseq(1,3,1)\n\n# embedded function : fun2(fun1())\nlength(c(1,2,3))\n# use pipe, \".\" is the result of previous step\nc(1,2,3) %&gt;% length(.)\n\n# replicate element as vector\nrep(1,3)\n# remove duplicates\nrep(1,3) %&gt;% unique()\n# cumulative sum \nrep(1,3) %&gt;% cumsum()\n\n# is there any difference?\npaste(c(\"a\",\"1\"),collapse = \"\")\npaste0(c(\"a\",\"1\"))\npaste0(\"a\",\"1\")\n\n\n\n\n\n\n\nchallenge\n\n\n\nWe introduced data type Date in Section 2.2, It actually behave like numeric sequence. You have Vector of type date, length is 1, value is “2023-04-17”.\n\ndate_element &lt;- as.Date('2023-04-17')\n\n\nHow to create date vector of length 5?\n\n\n\n[1] \"2023-04-17\" \"2023-04-18\" \"2023-04-19\" \"2023-04-20\" \"2023-04-21\"\n\n\n\nCould you do the average of this vector?\n\n\n\n\n\n\n\n\n\nchallenge\n\n\n\nUse str() to check the data type of variable in your environment.\nYou have two vectors,\n\nvec1&lt;-c(\"a\",\"b\")\nvec2&lt;-c(\"1\",\"2\")\n\nHow to use paste and repto create sequence of char vector shown below?\n\n\n[1] \"a1\" \"a2\" \"b1\" \"b2\"\n\n\n[1] \"a1\" \"b1\" \"a2\" \"b2\"\n\n\nCheck the arguments of rep to get more hints.\n\n?rep\n\ne.g.,\n\nrep(c(\"a\",\"b\"),each=2)\nrep(c(\"a\",\"b\"),times=2)\n\n\n\n\n\n3.3 write your first function\nformat: function_name(argument1, argument2) {code} example:\n\nplusone &lt;- function(x){\n  x+1\n}\n# is function data type sensitive?\nplusone(variable)\nplusone(Variable) \n\nfunction with good documentation example:\n\nfunction_name  &lt;-function(input){\n  # input: datatype, length, meaning.\n  # output: datatype, length, meaning.\n  # action1: intermediate_variable &lt;- input %&gt;% fun1()\n  # action2: output &lt;-intermediate_variable%&gt;% fun2()\n  ...\n  return(output)\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nwrite a function with documentation: input vec is a numeric vector with length 3, return str of average value of vec ± standard deviation of vec.\nVisualize the step in your function by first writing your the possible steps in text!"
  },
  {
    "objectID": "posts/Week1/index.html#r-packages-collection-of-functions",
    "href": "posts/Week1/index.html#r-packages-collection-of-functions",
    "title": "Week1: R studio and vector",
    "section": "4 r packages : collection of functions",
    "text": "4 r packages : collection of functions\nCheck this great package tidyverse!\n\nNote that windows user may need to first download the Rtools that match your R version.\n\nYou can check your R version by typing version() in your R console.\n\ninstall.packages(tidyrverse)\ninstall.packages(\"tidyrverse\")\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Week2/index.html#working-directory",
    "href": "posts/Week2/index.html#working-directory",
    "title": "Week2: Working directory and accessor",
    "section": "1 Working directory",
    "text": "1 Working directory\n\n1.1 preparation\n\nOpen the folder that contain Wheat_BSC_project.Rproj\ndownload the data from HU-box, save it in data.\ncreate Week2.R and save it in folder src.\n\n\n\n\n‘folder structure’\n\n\nWhat is working directory (wd)?\n\n\n1.2 abbreviation path: “.” for wd and “..” for parent of wd\n\".\" means the working directory (wd) where this R script exists.\n\"..\" means the parent (one level higher) directory of \".\".\n\n\n\n\n\n\nclick for example\n\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\n\n# working directory, abbreviated as \".\"\ngetwd()\n# parent directory, abbreviated as \"..\"\ndirname(getwd())\n# assign current path to variable\ncurrent_path &lt;- getwd()\n# check the type \ncurrent_path %&gt;% str()\n\n\n# check files in the directory\n\n# are they different?\n\".\" %&gt;% list.files(path=.)\ngetwd() %&gt;% list.files(path=.)\n\n# are they different?\n\"..\" %&gt;% list.files(path=.)\ngetwd() %&gt;% dirname() %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nchallenge\n\n\n\nAlthough the meaning of . is the same as getwd(), the content is depending on the environment you are working with.\nRight click R studio logo, open a new R studio window, compare the result of getwd() in R project and R\n\n\n\n\n1.3 accessing files and folder inside a R project\nWhich one do you prefer? Why do we prefer relative path?\n\n# absolute path, did you get error?\n\"C:/Users/marse/seadrive_root/Tien-Che/My Libraries/PhD_Tien/Project/Postdoc_teaching/BSC_project_IPFS2023/data\" %&gt;% list.files(path=.)\n# relative path in R base\nparent_path &lt;- getwd() \npaste0(parent_path,\"/data\") %&gt;% list.files(path=.)\n\n# Does this works? \n\".\\data\" %&gt;% list.files(path=.)\n\"data\" %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nchallenge\n\n\n\n\n\n\nsymbol\nAbsolute path\nrelative path\ncolor\n\n\n\n\nA\nC/users/Wheat_BSC_project\n..\nblack\n\n\nB\nC/users/Wheat_BSC_project/data\n?\nblue\n\n\nC\nC/users/Wheat_BSC_project/src\n.\nred\n\n\nD\nC/users/Wheat_BSC_project/src/data\n?\nblue\n\n\n\nBelow are four relative paths. Please rewrite them in absolute (full) path form. Which two are the same? Based on the figure illustated below, path 1-4 should be A,B,C or D?\n\n\"ear_summarized.csv\"\n\"data/ear_summarized.csv\"\n\"./data/ear_summarized.csv\"\n\"../data/ear_summarized.csv\""
  },
  {
    "objectID": "posts/Week2/index.html#get-element-from-a-vetor-with-accessors",
    "href": "posts/Week2/index.html#get-element-from-a-vetor-with-accessors",
    "title": "Week2: Working directory and accessor",
    "section": "2 get element from a vetor with accessors []",
    "text": "2 get element from a vetor with accessors []\nvector indexing start from 1 to the length of the vector. \n\nempty_vec &lt;- c()\nlength(empty_vec)\n# what is the type of the empty vec?\nempty_vec %&gt;% str()\n\n# NULL: empty \nempty_vec[1]\nempty_vec[0]\n\n\nvec &lt;- c(1,3,5)\nvec[1]\n#reorder the vector \nvec[c(2,1,3)]\n# removing the indexed elements\nvec[-1]\nvec[-2]\n\n# indexing start from 1, not 0\n# therefore you get, numeric(0)\nvec[0]\n# when access exceeding the range of a vector, what datatype do you get? \nvec[4]\nvec %&gt;% .[length(.)+1]\nvec[1:4]\nvec[4:1]\n\n# find specific element or position\nvec[c(F,T,F)]\nvec[vec==5]\n# when codition not match at all, it will return? \nvec[vec==2]\nvec[c(F,F,F)]\nvec %&gt;% .[c(F)]\nvec[vec==\"a\"]\n\n# default str vector\nletters\nLETTERS\n# when the query does not match, guess what will be the datatype? \nletters %&gt;% .[.==2]\nletters %&gt;% .[c(F)]\n# vector over write\nvec\nvec &lt;- c(2,1,3)\nvec\n\n\n\n\n\n\n\nchallenge\n\n\n\n\nvec &lt;- c(1, 2, 3, 4, 5)\nlogical_vec &lt;- c(TRUE, FALSE)\nsubset_vec &lt;- vec[logical_vec]\nsubset_vec\n\n[1] 1 3 5\n\n\nwhat did you observe? Is there any vector recycling?\nWhat happen when you enter vec[TRUE]?\n\n\nSupplementary information of special datatypes:\nEmpty : NULL\nIndexing at zero position:numeric(0)\n\n2.1 list: keep the diversity of data type\nlist_object&lt;- list(element_name=value) Make a list is like put a cookie(content of list element) in the cookie jar(list element).\nThere are 3 common accessors for list: 1. access the list element (cookie jar)\n[] access the list position\n\nacess the content of list element (cookie)\n\n[[]] access the content of a list element by position or name\n\nacess the specific content of list element (cookie) [[]][], position of logical vector\n\n\nvec_obj &lt;- c(1,2,4,5)\n# position vector\npos_vec &lt;- c(2,3,1)\nlist_obj &lt;- list(vec_obj)\n# element id\nele_ind &lt;- 1\n\n\n\n\n\n\n\n\n\naction\nvector\nlist\n\n\n\n\nextract from content\nvec_obj[pos_vec]\nlist_obj[[ele_ind]][pos_vec]\n\n\nshow content\nvec_obj\nlist_obj[[ele_ind]]\n\n\nrefer to position\n\nlist_obj[ele_ind]\n\n\n\n\n\n\nlist without name"
  },
  {
    "objectID": "posts/Week2/index.html#footnotes",
    "href": "posts/Week2/index.html#footnotes",
    "title": "Week2: Working directory and accessor",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n[accessors] (https://www.r-bloggers.com/2009/10/r-accessors-explained/)↩︎"
  },
  {
    "objectID": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html",
    "href": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html",
    "title": "Week2: Working directory and accessor",
    "section": "",
    "text": "Welcome to the second course! You will learn working directory, subset elements from vector, list and dataframe."
  },
  {
    "objectID": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#working-directory",
    "href": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#working-directory",
    "title": "Week2: Working directory and accessor",
    "section": "1 Working directory",
    "text": "1 Working directory\n\n1.1 preparation\n\nOpen the folder that contain Wheat_BSC_project.Rproj\ndownload the data from HU-box, save it in data.\ncreate Week2.R and save it in folder src.\n\n\n\n\n‘folder structure’\n\n\nWhat is working directory (wd)?\n\n\n1.2 abbreviation path: “.” for wd and “..” for parent of wd\n\".\" means the working directory (wd) where this R script exists.\n\"..\" means the parent (one level higher) directory of \".\".\n\n\n\n\nlibrary(dplyr)\n\n# working directory, abbreviated as \".\"\ngetwd()\n# parent directory, abbreviated as \"..\"\ndirname(getwd())\n# assign current path to variable\ncurrent_path &lt;- getwd()\n# check the type \ncurrent_path %&gt;% str()\n\n\n# check files in the directory\n\n# are they different?\n\".\" %&gt;% list.files(path=.)\ngetwd() %&gt;% list.files(path=.)\n\n# are they different?\n\"..\" %&gt;% list.files(path=.)\ngetwd() %&gt;% dirname() %&gt;% list.files(path=.)\n\n\nAlthough the meaning of . is the same as getwd(), the content is depending on the environment you are working with.\nRight click R studio logo, open a new R studio window, compare the result of getwd() in R project and R\n\n\n\n1.3 accessing files and folder inside a R project\nWhich one do you prefer? Why do we prefer relative path?\n\n# absolute path, did you get error?\n\"C:/Users/marse/seadrive_root/Tien-Che/My Libraries/PhD_Tien/Project/Postdoc_teaching/BSC_project_IPFS2023/data\" %&gt;% list.files(path=.)\n# relative path in R base\nparent_path &lt;- getwd() \npaste0(parent_path,\"/data\") %&gt;% list.files(path=.)\n\n# Does this works? \n\".\\data\" %&gt;% list.files(path=.)\n\"data\" %&gt;% list.files(path=.)\n\n\nread from relative path, which one is correct? Assume working directory current_path is \"C/users/Wheat_BSC_project/src\"\nAbsolute_path = current_path +\"/\"+relative_path Below are four relative paths. Please rewrite them in absolute (full) path form. What should . be replace? Which two are the same? Based on the figure illustated below, path 1-4 should be A,B,C or D?\n\n\"ear_summarized.csv\"\n\"data/ear_summarized.csv\"\n\"./data/ear_summarized.csv\"\n\"../data/ear_summarized.csv\""
  },
  {
    "objectID": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#get-element-from-a-vetor-with-accessors",
    "href": "posts/Week2/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#get-element-from-a-vetor-with-accessors",
    "title": "Week2: Working directory and accessor",
    "section": "2 get element from a vetor with accessors []",
    "text": "2 get element from a vetor with accessors []\nvector indexing start from 1 to the length of the vector. \n\nempty_vec &lt;- c()\nlength(empty_vec)\n# what is the type of the empty vec?\nempty_vec %&gt;% str()\n\n# NULL: empty \nempty_vec[1]\nempty_vec[0]\n\n\nvec &lt;- c(1,3,5)\nvec[1]\n#reorder the vector \nvec[c(2,1,3)]\n# removing the indexed elements\nvec[-1]\nvec[-2]\n\n# indexing start from 1, not 0\n# therefore you get, numeric(0)\nvec[0]\n# when access exceeding the range of a vector, what datatype do you get? \nvec[4]\nvec %&gt;% .[length(.)+1]\nvec[1:4]\nvec[4:1]\n\n# find specific element or position\nvec[c(F,T,F)]\nvec[vec==5]\n# when codition not match at all, it will return? \nvec[vec==2]\nvec[c(F,F,F)]\nvec %&gt;% .[c(F)]\nvec[vec==\"a\"]\n\n# default str vector\nletters\nLETTERS\n# when the query does not match, guess what will be the datatype? \nletters %&gt;% .[.==2]\nletters %&gt;% .[c(F)]\n# vector over write\nvec\nvec &lt;- c(2,1,3)\nvec\n\n\n\nvec &lt;- c(1, 2, 3, 4, 5)\nlogical_vec &lt;- c(TRUE, FALSE)\nsubset_vec &lt;- vec[logical_vec]\nsubset_vec\n\n[1] 1 3 5\n\n\nwhat did you observe? Is there any vector recycling?\nWhat happen when you enter vec[TRUE]?\n\nSupplementary information of special datatypes:\nEmpty : NULL\nIndexing at zero position:numeric(0)\n\n2.1 list: keep the diversity of data type\nlist_object&lt;- list(element_name=value) Make a list is like put a cookie(content of list element) in the cookie jar(list element).\nThere are 3 common accessors for list: 1. access the list element (cookie jar)\n[] access the list position\n\nacess the content of list element (cookie)\n\n[[]] access the content of a list element by position or name\n$ access the content of a list element by name\nlist_object$element_name or list_object[[element_name]]\n\n\n\nlist without name\n\n\n\n\n\nlist with name\n\n\nMore about the accessors. 11 accessors\n\n# create a simple list\nlist(1)\n# create a simple list with name \"x\" for first element\nlist(x=1)\nlist(x=1)[\"x\"]\n# extract content\nlist(x=1)$\"x\"\nlist(x=1)[[1]]\nlist(x=1)[[\"x\"]]\n\n# extract with pipe\nlist(x=1) %&gt;% .[[1]]\nlist(x=1) %&gt;% .$\"x\"\n\n# long list\nlong_list_example &lt;- list(1,c(1,2),\n                          T,c(T,T),\n                          \"str\",c(\"a\",\"b\"),\n                          list(1),\n                          mean,data.frame())\n# check structure of this list \n# list_complex_example %&gt;% str()\n# list_complex_example %&gt;% glimpse()\n# list_complex_example\n# first list \nlong_list_example[1]\n# content of first list\nlong_list_example[[1]]\n# first element of content of first list\nlong_list_example[[1]][1]\n\n\ncan you guess what data type are these?\n\n# non-sense\nlong_list_example[[1]][2]\nlong_list_example[1][1]\nlong_list_example[1][2]\nlong_list_example[2][2]\n# meaningful\nlong_list_example[[2]][2]\n\n\n\n\n2.2 lapply: return as a list\nlapply(vector, function) ?lapply\n\n# input is vector\nc(1,4) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input is list\nlist(2,4,c(1,4)) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input has differnt type\nlist(2,4,c(1,4),\"8\") %&gt;% \n  lapply(.,FUN=function(x){x+3})\n\n\nWhy you get error in the last line?\n\n\n\n2.3 dataframe is a special type of list\neach column has one data type\n\n# create a dataframe \ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\\temp=c(20,15,13),\\thermal_time=cumsum(c(20,15,13)))\n# another way\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) \ndf$temp=c(20,15,13)\ndf$thermal_time=cumsum(df$temp)\n\n# third method\nlibrary(dplyr)\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) %&gt;% \n  mutate(temp=c(20,15,13), \n         thermal_time=cumsum(temp))\ndf\n\n\nIs it possible to create data frame with vectors of different length?\n\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1), \n           temp=c(20,13))\n\n\n\n\n2.4 extract columns from data frame\nYou can subset dataframe by indexing [row,column]\ndataframe[,column] select the whole role for selected columnn\ndataframe[row,] select the whole column of selected rows\nSelect multiple row or column by puting logical or numeric vector in the square bracket.\n\nuse df,\n\nAccess column thermal_time as vector\nExtract temp when time is 2023-04-17\nExtract first row and first column with [1,]and [,1]\n\n\n\nif you want to turn a data frame (df) by 90 degree (“transpose”), which function can you use? Could you find the answer on google or chatGPT?"
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html",
    "title": "Week1: R studio and vector",
    "section": "",
    "text": "Welcome to the first course! During the following 2 hrs, you will learn data type of vectors, function and %&gt;%."
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#set-up-your-working-directory",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#set-up-your-working-directory",
    "title": "Week1: R studio and vector",
    "section": "1 Set up your working directory",
    "text": "1 Set up your working directory\n\n1.1 preparation\n\nPlease make sure you have installed R & Rstudio.\nFile -&gt; New Project -&gt; Wheat_BSC_project.Rproj\n\n\n### your first R script\nPress Ctrl+ Shift +Nto open new script.Save it as Week1_practice.R Copy code from this website to your script and press run.\n\n\n1.2 Concept of datatype & name space:\n\nDon’t overwrite variable names in name space (what already exists in system).\n\neg., var,mean,aov, etc.\n\n\n\n\n\n\n\n\nWarning\n\n\n\navoid something that will show in the drop down menu of auto-completion.\n\n\n\n\n\nSeparate long variable names with _.\n\neg., thermal_time,mean_yield, etc.\n\nDon’t start variable names with number.\n\n\n\n\n\nBad\nBetter\n\n\n\n\n\n3years\nthree_years\n\n\n\n1225measurement\nmeasurement_1225\n\n\n\n13genotypes\ngenotypes_13\n\n\n\n\n\n\nStructure of a vector\n\n\nVariable = variable names + object"
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#data-type-is-everything",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#data-type-is-everything",
    "title": "Week1: R studio and vector",
    "section": "2 Data type is everything",
    "text": "2 Data type is everything\n\nvariable\n# assignment str\"v\" to name \"variable\"\n## \"\" and unquote str and variable \nvariable &lt;- \"v\"\nVariable &lt;- 1\n\nvariable +1\nVariable +1 \n\n\n2.1 Always check your data type first!\n\n# str??\nstr\n?str\nstr(variable)\nstr(Variable)\n# data type coersion\nstr(NA)\nstr(c(NA,1))\nstr(c(NA,\"a\"))\nstr(c(NA,TRUE))\nstr(c(1,\"a\"))\n\n\n\n2.2 Date\n\nas.Date(\"2023-04-17\")\nas.Date(\"2023-04-17\",format=\"%Y-%m-%d\")\n# is ther any error?\nas.Date(\"20230417\")\nas.Date(\"17042023\")\n# additive properties of Date \nas.Date(\"2023-04-17\")-7\nas.Date(\"2023-04-17\")+2"
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#function-something-ends-with",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#function-something-ends-with",
    "title": "Week1: R studio and vector",
    "section": "3 Function: something ends with ()",
    "text": "3 Function: something ends with ()\n\n\n\nHow function works?\n\n\n\n# example: fun(object)\nc(1,2,3)\nmean(c(1,2,3))\nstr(TRUE)\nseq(1,5,1)\n\n\nSince type Date is additive, how to create successive date vector of length 5? Vector date start with “2023-04-17”\nCould you do the average of this vector?\n\n\n\n[1] \"2023-04-17\" \"2023-04-18\" \"2023-04-19\" \"2023-04-20\" \"2023-04-21\"\n\n\n\n3.1 separate individual function from nested functions with %&gt;%\nPipe (%&gt;%) is available in r-package either dplyr or magrittr.\nPlease use %&gt;% to avoid embedded functions.\n.stands for the result from the left side of the pipe.\nFor long line code, press enter after each %&gt;%.\nSelect all the codes by ctrl A.\nIndent the selected codes by ctrl I.\nConcepts of using pipe\n\n# syntax of using pipe\n\nfun1(object)\n\nobject %&gt;% fun1(.)\nobject %&gt;% fun1()\nobject %&gt;% fun1() %&gt;% .\nobject %&gt;% fun1(.) %&gt;% .\n\n#embedded functions\nfun2(fun1(object))\n# pipe\nobject %&gt;% \n  fun1() %&gt;% \n  fun2()\n\nExamples of using pipe\n\n# how many ways of creating a sequence?\nc(1,2,3)\nseq(1,3,1)\n\n# embedded function : fun2(fun1())\nlength(c(1,2,3))\n# use pipe, \".\" is the result of previous step\nc(1,2,3) %&gt;% length(.)\n\n# replicate element as vector\nrep(1,3)\n# remove duplicates\nrep(1,3) %&gt;% unique()\n# cumulative sum \nrep(1,3) %&gt;% cumsum()\n\n# is there any difference?\npaste(c(\"a\",\"1\"),collapse = \"\")\npaste0(c(\"a\",\"1\"))\npaste0(\"a\",\"1\")\n\n\nUse str() to check the data type of above line.\nYou have two vectors, c(\"a\",\"b\") and c(\"1\",\"2\")\nHow to use paste and repto create sequence of char vector shown below?\nCheck the arguments of rep to get more hints. e.g.,\nrep(c(\"a\",\"b\"),each=2)\nrep(c(\"a\",\"b\"),times=2)\n\n\n\n[1] \"a1\" \"a2\" \"b1\" \"b2\"\n\n\n[1] \"a1\" \"b1\" \"a2\" \"b2\"\n\n\n\n\n3.2 write your first function\nformat: function_name(argument1, argument2) {code} example:\n\nplusone &lt;- function(x){\n  x+1\n}\n# is function data type sensitive?\nplusone(variable)\nplusone(Variable) \n\nfunction with good documentation example:\n\nfunction_name  &lt;-function(input){\n  # input: datatype, length, meaning.\n  # output: datatype, length, meaning.\n  # action1: intermediate_variable &lt;- input %&gt;% fun1()\n  # action2: output &lt;-intermediate_variable%&gt;% fun2()\n  ...\n  return(output)\n}\n\n\nwrite a function with documentation: input vec is a numeric vector with length 3, return str of average value of vec ± standard deviation of vec.\nVisualize the step in your function by first writing your the possible steps in text!"
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#r-packages-collection-of-functions",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#r-packages-collection-of-functions",
    "title": "Week1: R studio and vector",
    "section": "4 r packages : collection of functions",
    "text": "4 r packages : collection of functions\nCheck this great package tidyverse!\n\nNote that windows user may need to first download the Rtools that match your R version.\n\nYou can check your R version by typing version() in your R console.\n\ninstall.packages(tidyrverse)\ninstall.packages(\"tidyrverse\")\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#pattern-matching-logical-vector-and-its-position",
    "href": "posts/Week1/index (SFConflict wangtien@hu-berlin.de 2023-10-30-18-22-55).html#pattern-matching-logical-vector-and-its-position",
    "title": "Week1: R studio and vector",
    "section": "5 Pattern matching: logical vector and its position",
    "text": "5 Pattern matching: logical vector and its position\n\n\n\nLogical vector\n\n\n\n# check if pattern exist in vector\n3%in%c(1,3) \n2%in%c(1,3) \n\n1==2 \n!1==2 \n1!=2 \nc(1,3)==2\n\nwhich(c(1,3)==3) \n\n# what will be the difference?\norder(c(3,1,2)) \nc(3,1,2) %&gt;% .[order(.)]\n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#pattern-matching-logical-vector-and-its-position",
    "href": "posts/Week2/index.html#pattern-matching-logical-vector-and-its-position",
    "title": "Week2: Working directory and accessor",
    "section": "1 Pattern matching: logical vector and its position",
    "text": "1 Pattern matching: logical vector and its position\n\n\n\nLogical vector\n\n\nOperators\n\nL==R: direction doesn’t matters.\nL%in%R: one sided, check if object L is presence in R.\n!: negate the logical vector.\n\n\n# check if pattern exist in vector\n3%in%c(1,3)\n# what is the difference?\nc(1,3)%in%3\n\n2%in%c(1,3) \n\n1==2 \n1==c(2,1) \n# elementwise check whether L equals\nc(2,1)==1\n# check identity pairwise\nc(1,2)==c(2,4)\n\n# is '!' reverse the logical vector?\n!1==2 \n1!=2 \nc(1,3)==2\n# what does which() returns?\nwhich(c(1,3)==3) \n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#conditions-logical-vector-and-operators",
    "href": "posts/Week2/index.html#conditions-logical-vector-and-operators",
    "title": "Week2: Working directory and accessor",
    "section": "1 Conditions: logical vector and operators",
    "text": "1 Conditions: logical vector and operators\n Logical operators [^3] [^3]:(https://www.statmethods.net/management/operators.html)\n\nL==R: direction doesn’t matters.\nL%in%R: one sided, check if object L is presence in R.\n!: negate the logical vector.\n\n\n# check if pattern exist in vector\n3%in%c(1,3)\n# what is the difference?\nc(1,3)%in%3\n\n2%in%c(1,3) \n\n1==2 \n1==c(2,1) \n# elementwise check whether L equals\nc(2,1)==1\n# check identity pairwise\nc(1,2)==c(2,4)\n\n# is '!' reverse the logical vector?\n!1==2 \n1!=2 \nc(1,3)==2\n# what does which() returns?\nwhich(c(1,3)==3) \n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\nPreconditions examples inside a function\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#conditions-logical-vector-and-operators3",
    "href": "posts/Week2/index.html#conditions-logical-vector-and-operators3",
    "title": "Week2: Working directory and accessor",
    "section": "1 Conditions: logical vector and operators11 (https://www.statmethods.net/management/operators.html)",
    "text": "1 Conditions: logical vector and operators11 (https://www.statmethods.net/management/operators.html)\n\n\n\nLogical vector\n\n\n\nL==R: direction doesn’t matters.\nL%in%R: one sided, check if object L is presence in R.\n!: negate the logical vector.\n\n\n# check if pattern exist in vector\n3%in%c(1,3)\n# what is the difference?\nc(1,3)%in%3\n\n2%in%c(1,3) \n\n1==2 \n1==c(2,1) \n# elementwise check whether L equals\nc(2,1)==1\n# check identity pairwise\nc(1,2)==c(2,4)\n\n# is '!' reverse the logical vector?\n!1==2 \n1!=2 \nc(1,3)==2\n# what does which() returns?\nwhich(c(1,3)==3) \n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\nPreconditions examples inside a function\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#conditions-logical-vector-and-operators-3",
    "href": "posts/Week2/index.html#conditions-logical-vector-and-operators-3",
    "title": "Week2: Working directory and accessor",
    "section": "1 Conditions: logical vector and operators 11 (https://www.statmethods.net/management/operators.html)",
    "text": "1 Conditions: logical vector and operators 11 (https://www.statmethods.net/management/operators.html)\n\n\n\nLogical vector\n\n\n\nL==R: direction doesn’t matters.\nL%in%R: one sided, check if object L is presence in R.\n!: negate the logical vector.\n\n\n# check if pattern exist in vector\n3%in%c(1,3)\n# what is the difference?\nc(1,3)%in%3\n\n2%in%c(1,3) \n\n1==2 \n1==c(2,1) \n# elementwise check whether L equals\nc(2,1)==1\n# check identity pairwise\nc(1,2)==c(2,4)\n\n# is '!' reverse the logical vector?\n!1==2 \n1!=2 \nc(1,3)==2\n# what does which() returns?\nwhich(c(1,3)==3) \n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\nPreconditions examples inside a function\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#conditions-logical-operators-and-vectors",
    "href": "posts/Week2/index.html#conditions-logical-operators-and-vectors",
    "title": "Week2: Working directory and accessor",
    "section": "1 Conditions: logical operators and vectors",
    "text": "1 Conditions: logical operators and vectors\n Logical operators 11 (https://www.statmethods.net/management/operators.html)\n\nL==R: direction doesn’t matters.\nL%in%R: one sided, check if object L is presence in R.\n!: negate the logical vector.\n\n\n# check if pattern exist in vector\n3%in%c(1,3)\n# what is the difference?\nc(1,3)%in%3\n\n2%in%c(1,3) \n\n1==2 \n1==c(2,1) \n# elementwise check whether L equals\nc(2,1)==1\n# check identity pairwise\nc(1,2)==c(2,4)\n\n# is '!' reverse the logical vector?\n!1==2 \n1!=2 \nc(1,3)==2\n# what does which() returns?\nwhich(c(1,3)==3) \n\n# what will be the data type? check with str()\nc(1,2,NA) %&gt;% is.na() \nc(1,2,NA) %&gt;% is.na() %&gt;% which() \nc(1,2,NA) %&gt;% is.na() %&gt;% !.\nc(1,2,NA) %&gt;% !is.na() \n!is.na(c(1,2,NA))\n\nPreconditions examples inside a function\n\n# check if data type match\narg &lt;- \"\"\nis.character(arg)\nif(is.character(arg)){\n  print(\"character\")\n}\n\nif(is.character(arg)){\n  print(\"character\")\n}else{\n  error(\"type other than character\")\n}\n\nif(is.character(arg)){\n  warning(\"wrong\")\n}\n\nif(is.character(arg)){\n  stop(\"wrong\")\n}\n\n\n\n\n\n\n\nchallenge\n\n\n\nInside your plusone function, please check first whether input x is numeric, then proceed the process.\nif not, return with message “wrong input type” using stop()"
  },
  {
    "objectID": "posts/Week2/index.html#working-directory-wd",
    "href": "posts/Week2/index.html#working-directory-wd",
    "title": "Week2: Working directory and accessor",
    "section": "2 Working directory (wd)",
    "text": "2 Working directory (wd)\n\".\" means the working directory (wd), the path in which R.project exists.\n\"..\" means the parent (one level higher) directory of \".\".\n\n\n\n\n\n\nclick for example\n\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\n\n# working directory, abbreviated as \".\"\ngetwd()\n# parent directory, abbreviated as \"..\"\ndirname(getwd())\n# assign current path to variable\ncurrent_path &lt;- getwd()\n# check the type \ncurrent_path %&gt;% str()\n\n\n# check files in the directory\n\n# are they different?\n\".\" %&gt;% list.files(path=.)\ngetwd() %&gt;% list.files(path=.)\n\n# are they different?\n\"..\" %&gt;% list.files(path=.)\ngetwd() %&gt;% dirname() %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nchallenge\n\n\n\nAlthough the meaning of . is the same as getwd(), the content is depending on the environment you are working with.\nRight click R studio logo, open a new R studio window, compare the result of getwd() in R project and R\n\n\n\n2.1 accessing files and folder inside a R project\nWhich one do you prefer? Why do we prefer relative path?\n\n# absolute path, did you get error?\n\"C:/Users/marse/seadrive_root/Tien-Che/My Libraries/PhD_Tien/Project/Postdoc_teaching/BSC_project_IPFS2023/data\" %&gt;% list.files(path=.)\n# relative path in R base\nparent_path &lt;- getwd() \npaste0(parent_path,\"/data\") %&gt;% list.files(path=.)\n\n# Does this works? \n\".\\data\" %&gt;% list.files(path=.)\n\"data\" %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nchallenge\n\n\n\nread from relative path, which one is correct? Assume working directory current_path is \"C/users/Wheat_BSC_project/src\"\nAbsolute_path = current_path +\"/\"+relative_path Below are four relative paths. Please rewrite them in absolute (full) path form. What should . be replace? Which two are the same? Based on the figure illustated below, path 1-4 should be A,B,C or D?\n\n\"ear_summarized.csv\"\n\"data/ear_summarized.csv\"\n\"./data/ear_summarized.csv\"\n\"../data/ear_summarized.csv\""
  },
  {
    "objectID": "posts/Week2/index.html#note-that-you-can-also-assess-content-by-name",
    "href": "posts/Week2/index.html#note-that-you-can-also-assess-content-by-name",
    "title": "Week2: Working directory and accessor",
    "section": "3 note that you can also assess content by name",
    "text": "3 note that you can also assess content by name\n$ access the content of a list element by name list_object$element_name or list_object[[element_name]] \nMore about the accessors. 11 accessors\n\n# create a simple list\nlist(1)\n# create a simple list with name \"x\" for first element\nlist(x=1)\nlist(x=1)[\"x\"]\n# extract content\nlist(x=1)$\"x\"\nlist(x=1)[[1]]\nlist(x=1)[[\"x\"]]\n\n# extract with pipe\nlist(x=1) %&gt;% .[[1]]\nlist(x=1) %&gt;% .$\"x\"\n\n# long list\nlong_list_example &lt;- list(1,c(1,2),\n                          T,c(T,T),\n                          \"str\",c(\"a\",\"b\"),\n                          list(1),\n                          mean,data.frame())\n# check structure of this list \n# list_complex_example %&gt;% str()\n# list_complex_example %&gt;% glimpse()\n# list_complex_example\n# first list \nlong_list_example[1]\n# content of first list\nlong_list_example[[1]]\n# first element of content of first list\nlong_list_example[[1]][1]\n\n\n\n\n\n\n\nchallenge\n\n\n\ncan you guess what data type are these?\n\n# non-sense\nlong_list_example[[1]][2]\nlong_list_example[1][1]\nlong_list_example[1][2]\nlong_list_example[2][2]\n# meaningful\nlong_list_example[[2]][2]\n\n\n\n\n3.1 lapply: return as a list\nlapply(vector, function) ?lapply\n\n# input is vector\nc(1,4) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input is list\nlist(2,4,c(1,4)) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input has differnt type\nlist(2,4,c(1,4),\"8\") %&gt;% \n  lapply(.,FUN=function(x){x+3})\n\n\n\n\n\n\n\nchallenge\n\n\n\nWhy you get error in the last line?\n\n\n\n\n3.2 dataframe is a special type of list\neach column has one data type\n\n# create a dataframe \ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\\temp=c(20,15,13),\\thermal_time=cumsum(c(20,15,13)))\n# another way\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) \ndf$temp=c(20,15,13)\ndf$thermal_time=cumsum(df$temp)\n\n# third method\nlibrary(dplyr)\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) %&gt;% \n  mutate(temp=c(20,15,13), \n         thermal_time=cumsum(temp))\ndf\n\n\n\n\n\n\n\nchallenge\n\n\n\nIs it possible to create data frame with vectors of different length?\n\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1), \n           temp=c(20,13))\n\n\n\n\n\n3.3 extract columns from data frame\nYou can subset dataframe by indexing [row,column]\ndataframe[,column] select the whole role for selected columnn\ndataframe[row,] select the whole column of selected rows\nSelect multiple row or column by puting logical or numeric vector in the square bracket.\n\n\n\n\n\n\nchallenge\n\n\n\nuse df,\n\nAccess column thermal_time as vector\nExtract temp when time is 2023-04-17\nExtract first row and first column with [1,]and [,1]\n\n\n\n\nif you want to turn a data frame (df) by 90 degree (“transpose”), which function can you use? Could you find the answer on google or chatGPT?"
  },
  {
    "objectID": "posts/Week2/index.html#accessing-files-and-folder-inside-a-r-project",
    "href": "posts/Week2/index.html#accessing-files-and-folder-inside-a-r-project",
    "title": "Week2: Working directory and accessor",
    "section": "2.3 accessing files and folder inside a R project",
    "text": "2.3 accessing files and folder inside a R project\nWhich one do you prefer? Why do we prefer relative path?\n\n# absolute path, did you get error?\n\"C:/Users/marse/seadrive_root/Tien-Che/My Libraries/PhD_Tien/Project/Postdoc_teaching/BSC_project_IPFS2023/data\" %&gt;% list.files(path=.)\n# relative path in R base\nparent_path &lt;- getwd() \npaste0(parent_path,\"/data\") %&gt;% list.files(path=.)\n\n# Does this works? \n\".\\data\" %&gt;% list.files(path=.)\n\"data\" %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nclick for example\n\n\n\n\n\n\n\n\nsymbol\nAbsolute path\nrelative path\ncolor\n\n\n\n\nA\nC/users/Wheat_BSC_project\n..\nblack\n\n\nB\nC/users/Wheat_BSC_project/data\n?\nblue\n\n\nC\nC/users/Wheat_BSC_project/src\n.\nred\n\n\nD\nC/users/Wheat_BSC_project/src/data\n?\nblue\n\n\n\nBelow are four relative paths. Please rewrite them in absolute (full) path form. Which two are the same? Based on the figure illustated below, path 1-4 should be A,B,C or D?\n\n\"ear_summarized.csv\"\n\"data/ear_summarized.csv\"\n\"./data/ear_summarized.csv\"\n\"../data/ear_summarized.csv\""
  },
  {
    "objectID": "posts/Week2/index.html#list-keep-the-diversity-of-data-type",
    "href": "posts/Week2/index.html#list-keep-the-diversity-of-data-type",
    "title": "Week2: Working directory and accessor",
    "section": "2.1 list: keep the diversity of data type",
    "text": "2.1 list: keep the diversity of data type\nlist_object&lt;- list(element_name=value) Make a list is like put a cookie(content of list element) in the cookie jar(list element).\nThere are 3 common accessors for list: 1. access the list element (cookie jar)\n[] access the list position\n\nacess the content of list element (cookie)\n\n[[]] access the content of a list element by position or name\n\nacess the specific content of list element (cookie) [[]][], position of logical vector\n\n\nvec_obj &lt;- c(1,2,4,5)\n# position vector\npos_vec &lt;- c(2,3,1)\nlist_obj &lt;- list(vec_obj)\n# element id\nele_ind &lt;- 1\n\n\n\n\n\n\n\n\n\naction\nvector\nlist\n\n\n\n\nextract from content\nvec_obj[pos_vec]\nlist_obj[[ele_ind]][pos_vec]\n\n\nshow content\nvec_obj\nlist_obj[[ele_ind]]\n\n\nrefer to position\n\nlist_obj[ele_ind]\n\n\n\n\n# list without element name\nlist_a &lt;- list(c(1,2))\n\n\n\n\nlist without name\n\n\n\n2.1.1 note that you can also assess content by name\n$ access the content of a list element by name list_object$element_name or list_object[[element_name]]\n\n# list without element name\nlist_b &lt;- list(nam=c(1,2))\n\n\n\n\nlist with name\n\n\nMore about the accessors. 11 accessors\n\n# create a simple list\nlist(1)\n# create a simple list with name \"x\" for first element\nlist(x=1)\nlist(x=1)[\"x\"]\n# extract content\nlist(x=1)$\"x\"\nlist(x=1)[[1]]\nlist(x=1)[[\"x\"]]\n\n# extract with pipe\nlist(x=1) %&gt;% .[[1]]\nlist(x=1) %&gt;% .$\"x\"\n\n# long list\nlong_list_example &lt;- list(1,c(1,2),\n                          T,c(T,T),\n                          \"str\",c(\"a\",\"b\"),\n                          list(1),\n                          mean,data.frame())\n# check the content\nlong_list_example\n# check structure of this list \n# list_complex_example %&gt;% str()\n# list_complex_example %&gt;% glimpse()\n# list_complex_example\n# first list \nlong_list_example[1]\n# content of first list\nlong_list_example[[1]]\n# first element of content of first list\nlong_list_example[[1]][1]\n\n\n\n\n\n\n\nchallenge\n\n\n\ncan you guess what data type are these?\n\n# non-sense\nlong_list_example[[1]][2]\nlong_list_example[1][1]\nlong_list_example[1][2]\nlong_list_example[2][2]\n# meaningful\nlong_list_example[[2]][2]"
  },
  {
    "objectID": "posts/Week2/index.html#lapply-return-as-a-list",
    "href": "posts/Week2/index.html#lapply-return-as-a-list",
    "title": "Week2: Working directory and accessor",
    "section": "4.2 lapply: return as a list",
    "text": "4.2 lapply: return as a list\nlapply(vector, function) ?lapply\n\n# input is vector\nc(1,4) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input is list\nlist(2,4,c(1,4)) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input has differnt type\nlist(2,4,c(1,4),\"8\") %&gt;% \n  lapply(.,FUN=function(x){x+3})\n\n\n\n\n\n\n\nchallenge\n\n\n\nWhy you get error in the last line?"
  },
  {
    "objectID": "posts/Week2/index.html#dataframe-is-a-special-type-of-list",
    "href": "posts/Week2/index.html#dataframe-is-a-special-type-of-list",
    "title": "Week2: Working directory and accessor",
    "section": "2.3 dataframe is a special type of list",
    "text": "2.3 dataframe is a special type of list\neach column has one data type\n\n# create a dataframe \ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1),\\temp=c(20,15,13),\\thermal_time=cumsum(c(20,15,13)))\n# another way\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) \ndf$temp=c(20,15,13)\ndf$thermal_time=cumsum(df$temp)\n\n# third method\nlibrary(dplyr)\ndf &lt;- data.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1)) %&gt;% \n  mutate(temp=c(20,15,13), \n         thermal_time=cumsum(temp))\ndf\n\n\n\n\n\n\n\nchallenge\n\n\n\nIs it possible to create data frame with vectors of different length?\n\ndata.frame(time=as.Date(\"2023-04-16\",format=\"%Y-%m-%d\")+seq(1,3,1), \n           temp=c(20,13))\n\n\n\n\n2.3.1 extract columns from data frame\nYou can subset dataframe by indexing [row,column]\ndataframe[,column] select the whole role for selected columnn\ndataframe[row,] select the whole column of selected rows\nSelect multiple row or column by puting logical or numeric vector in the square bracket.\n\n\n\n\n\n\nchallenge\n\n\n\nuse df,\n\nAccess column thermal_time as vector\nExtract temp when time is 2023-04-17\nExtract first row and first column with [1,]and [,1]\n\n\n\n\nif you want to turn a data frame (df) by 90 degree (“transpose”), which function can you use? Could you find the answer on google or chatGPT?"
  },
  {
    "objectID": "posts/Week2/index.html#extract-columns-from-data-frame",
    "href": "posts/Week2/index.html#extract-columns-from-data-frame",
    "title": "Week2: Working directory and accessor",
    "section": "5.1 extract columns from data frame",
    "text": "5.1 extract columns from data frame\nYou can subset dataframe by indexing [row,column]\ndataframe[,column] select the whole role for selected columnn\ndataframe[row,] select the whole column of selected rows\nSelect multiple row or column by puting logical or numeric vector in the square bracket.\n\n\n\n\n\n\nchallenge\n\n\n\nuse df,\n\nAccess column thermal_time as vector\nExtract temp when time is 2023-04-17\nExtract first row and first column with [1,]and [,1]\n\n\n\n\nif you want to turn a data frame (df) by 90 degree (“transpose”), which function can you use? Could you find the answer on google or chatGPT?"
  },
  {
    "objectID": "posts/Week2/index.html#access-content-by-name",
    "href": "posts/Week2/index.html#access-content-by-name",
    "title": "Week2: Working directory and accessor",
    "section": "4.1 access content by name",
    "text": "4.1 access content by name\n$ access the content of a list element by name list_object$element_name or list_object[[element_name]]\n\n# list without element name\nlist_b &lt;- list(nam=c(1,2))\n\n\n\n\nlist with name\n\n\nMore about the accessors. 33 accessors\n\n# create a simple list\nlist(1)\n# create a simple list with name \"x\" for first element\nlist(x=1)\nlist(x=1)[\"x\"]\n# extract content\nlist(x=1)$\"x\"\nlist(x=1)[[1]]\nlist(x=1)[[\"x\"]]\n\n# extract with pipe\nlist(x=1) %&gt;% .[[1]]\nlist(x=1) %&gt;% .$\"x\"\n\n# long list\nlong_list_example &lt;- list(1,c(1,2),\n                          T,c(T,T),\n                          \"str\",c(\"a\",\"b\"),\n                          list(1),\n                          mean,data.frame())\n# check the content\nlong_list_example\n# check structure of this list \n# list_complex_example %&gt;% str()\n# list_complex_example %&gt;% glimpse()\n# list_complex_example\n# first list \nlong_list_example[1]\n# content of first list\nlong_list_example[[1]]\n# first element of content of first list\nlong_list_example[[1]][1]\n\n\n\n\n\n\n\nchallenge\n\n\n\ncan you guess what data type are these?\n\n# non-sense\nlong_list_example[[1]][2]\nlong_list_example[1][1]\nlong_list_example[1][2]\nlong_list_example[2][2]\n# meaningful\nlong_list_example[[2]][2]"
  },
  {
    "objectID": "posts/Week2/index.html#preparation",
    "href": "posts/Week2/index.html#preparation",
    "title": "Week2: Working directory and accessor",
    "section": "2.1 preparation",
    "text": "2.1 preparation\n\nOpen the folder that contain Wheat_BSC_project.Rproj\ndownload the data from HU-box, save it in data.\ncreate Week2.R and save it in folder src.\n\n\n\n\n‘folder structure’\n\n\nWhat is working directory (wd)?"
  },
  {
    "objectID": "posts/Week2/index.html#abbreviation-path-.-for-wd-and-..-for-parent-of-wd",
    "href": "posts/Week2/index.html#abbreviation-path-.-for-wd-and-..-for-parent-of-wd",
    "title": "Week2: Working directory and accessor",
    "section": "2.2 abbreviation path: “.” for wd and “..” for parent of wd",
    "text": "2.2 abbreviation path: “.” for wd and “..” for parent of wd\n\".\" means the working directory (wd) where this R script exists.\n\"..\" means the parent (one level higher) directory of \".\".\n\n\n\n\n\n\nclick for example\n\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\n\n# working directory, abbreviated as \".\"\ngetwd()\n# parent directory, abbreviated as \"..\"\ndirname(getwd())\n# assign current path to variable\ncurrent_path &lt;- getwd()\n# check the type \ncurrent_path %&gt;% str()\n\n\n# check files in the directory\n\n# are they different?\n\".\" %&gt;% list.files(path=.)\ngetwd() %&gt;% list.files(path=.)\n\n# are they different?\n\"..\" %&gt;% list.files(path=.)\ngetwd() %&gt;% dirname() %&gt;% list.files(path=.)\n\n\n\n\n\n\n\nchallenge\n\n\n\nAlthough the meaning of . is the same as getwd(), the content is depending on the environment you are working with.\nRight click R studio logo, open a new R studio window, compare the result of getwd() in R project and R"
  },
  {
    "objectID": "posts/Week2/index.html#lapply-apply-functions-and-return-list",
    "href": "posts/Week2/index.html#lapply-apply-functions-and-return-list",
    "title": "Week2: Working directory and accessor",
    "section": "4.2 lapply: apply functions and return list",
    "text": "4.2 lapply: apply functions and return list\nlapply(vector, function) ?lapply\n\n# input is vector\nc(1,4) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input is list\nlist(2,4,c(1,4)) %&gt;% \n  lapply(.,FUN=function(x){x+3})\n# input has differnt type\nlist(2,4,c(1,4),\"8\") %&gt;% \n  lapply(.,FUN=function(x){x+3})\n\n\n\n\n\n\n\nchallenge\n\n\n\nWhy you get error in the last line?"
  },
  {
    "objectID": "project_description.html#slides-prsentation",
    "href": "project_description.html#slides-prsentation",
    "title": "Project description",
    "section": "Slides prsentation",
    "text": "Slides prsentation\n\npage number\nunit of each axis in each figure\ntext size &gt; 20\n15 min not more than 15 slides"
  },
  {
    "objectID": "project_description.html#github",
    "href": "project_description.html#github",
    "title": "Project description",
    "section": "3 Reproducibility of your repo",
    "text": "3 Reproducibility of your repo\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nEvaluation will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.\nexample\n\n3.1 ReadMe\nFor each repo, include the following:\n\n3.1.1 Introduction and data\n\nDescribe the observations and the general characteristics being measured in the data\n\n\n\n3.1.2 Research question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\n3.1.3 Glimpse of data\n\nUse the glimpse function to provide an overview of each data set Example dataset code repo"
  },
  {
    "objectID": "project_description.html#slides",
    "href": "project_description.html#slides",
    "title": "Project description",
    "section": "4 Final prsentation",
    "text": "4 Final prsentation\n\n4.1 sturcture\nThe presentation neatly prepared and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. All code, warnings, and messages are suppressed. Presentation is in time.\nYou need to create presentation slides and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Previous research that relevant to your hypothess\nSlide 3: Hypotheses Research questions\nSlide 4: Introduce the data\nSlide 5: Calculation\nSlide n: Conclustions= 3 take home messages\n\n\n\n4.2 reminder\n\npage number\nunit of each axis in each figure\ntext size &gt; 20\n15 min not more than 15 slides\n3 take home messages in the last slide as conclusion"
  },
  {
    "objectID": "project_description.html#grading",
    "href": "project_description.html#grading",
    "title": "Project description",
    "section": "6 Grading criteria",
    "text": "6 Grading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n6.1 Methodology\nThis section includes a brief description of your modeling process.\n\n6.1.1 Grading criteria\nThe analysis steps are appropriate for the data and research question.\n\n\n\n6.2 Results\nDescribe the key results from the graph. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n6.2.1 Grading criteria\nThe visualization is clearly assessed, and interesting findings are clearly described. Interpretations of statistical test are used to support the key findings and conclusions, rather than merely visual comparison.\n\n\n\n6.3 Discussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n6.3.1 Grading criteria\nOverall conclusions from analysis are clearly described, and the statistical results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n6.4 Organization + formatting\nThis is an assessment of the overall presentation and formatting of the written report."
  }
]